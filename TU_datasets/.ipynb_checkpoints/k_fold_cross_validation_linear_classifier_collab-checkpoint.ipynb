{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d26202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import time\n",
    "from itertools import product\n",
    "from json import dumps\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.loader import DataListLoader, DataLoader\n",
    "from torch_geometric.nn import DataParallel\n",
    "from torch_geometric.seed import seed_everything\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data import DataLoader, Data\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pytorch_metric_learning.losses import NTXentLoss, VICRegLoss\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "import train_utils\n",
    "from data_utils import extract_edge_attributes\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from layers.input_encoder import LinearEncoder, LinearEdgeEncoder\n",
    "from layers.layer_utils import make_gnn_layer\n",
    "from models.GraphClassification import GraphClassification\n",
    "from models.model_utils import make_GNN\n",
    "\n",
    "import GCL.losses as L\n",
    "import GCL.augmentors as A\n",
    "from GCL.eval import get_split, SVMEvaluator, LREvaluator\n",
    "from GCL.models import DualBranchContrast\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6055974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--feature_augmentation'], dest='feature_augmentation', nargs=None, const=None, default=False, type=<class 'bool'>, choices=None, required=False, help='If true, feature augmentation.', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Augmentation\n",
    "# parser = argparse.ArgumentParser(f'arguments for training and testing')\n",
    "# parser.add_argument('--save_dir', type=str, default='./save', help='Base directory for saving information.')\n",
    "# parser.add_argument('--seed', type=int, default=2, help='Random seed for reproducibility.')\n",
    "# parser.add_argument('--dataset_name', type=str, default=\"COLLAB\",\n",
    "#                     choices=(\"MUTAG\", \"PROTEINS\", \"PTC_MR\", \"IMDBBINARY\", \"COLLAB\"), help='Name of dataset')\n",
    "# parser.add_argument('--drop_prob', type=float, default=0.5,\n",
    "#                     help='Probability of zeroing an activation in dropout layers.') \n",
    "# parser.add_argument('--batch_size', type=int, default=32, help='Batch size per GPU. Scales automatically when \\\n",
    "#                         multiple GPUs are available.')\n",
    "# parser.add_argument(\"--parallel\", action=\"store_true\",\n",
    "#                     help=\"If true, use DataParallel for multi-gpu training\")\n",
    "# parser.add_argument('--num_workers', type=int, default=0, help='Number of worker.')\n",
    "# parser.add_argument('--load_path', type=str, default=None, help='Path to load as a model checkpoint.')\n",
    "# parser.add_argument('--lr', type=float, default=0.001, help='Learning rate.')\n",
    "# parser.add_argument('--l2_wd', type=float, default=3e-3, help='L2 weight decay.')\n",
    "# parser.add_argument('--num_epochs', type=int, default=100, help='Number of epochs.')\n",
    "# parser.add_argument(\"--hidden_size\", type=int, default=128, help=\"Hidden size of the model\")\n",
    "# parser.add_argument(\"--embedding_size\", type=int, default=16, help=\"Output size of the logistic model\")\n",
    "# parser.add_argument(\"--model_name\", type=str, default=\"KHopGNNConv\",\n",
    "#                     choices=(\"KHopGNNConv\"), help=\"Base GNN model\")\n",
    "# parser.add_argument(\"--K\", type=int, default=2, help=\"Number of hop to consider\")\n",
    "# parser.add_argument(\"--num_layer\", type=int, default=2, help=\"Number of layer for feature encoder\")\n",
    "# parser.add_argument(\"--JK\", type=str, default=\"sum\", choices=(\"sum\", \"max\", \"mean\", \"attention\", \"last\", \"concat\"),\n",
    "#                     help=\"Jumping knowledge method\")\n",
    "# parser.add_argument(\"--residual\", default=True, action=\"store_true\", help=\"If true, use residual connection between each layer\")\n",
    "# parser.add_argument(\"--virtual_node\", action=\"store_true\", default=False, \n",
    "#                     help=\"If true, add virtual node information in each layer\")\n",
    "# parser.add_argument(\"--eps\", type=float, default=0., help=\"Initial epsilon in GIN\")\n",
    "# parser.add_argument(\"--train_eps\", action=\"store_true\", help=\"If true, the epsilon in GIN model is trainable\")\n",
    "# parser.add_argument(\"--combine\", type=str, default=\"geometric\", choices=(\"attention\", \"geometric\"),\n",
    "#                     help=\"Combine method in k-hop aggregation\")\n",
    "# parser.add_argument(\"--pooling_method\", type=str, default=\"sum\", choices=(\"mean\", \"sum\", \"attention\"),\n",
    "#                     help=\"Pooling method in graph classification\")\n",
    "# parser.add_argument('--norm_type', type=str, default=\"Batch\",\n",
    "#                     choices=(\"Batch\", \"Layer\", \"Instance\", \"GraphSize\", \"Pair\"),\n",
    "#                     help=\"Normalization method in model\")\n",
    "# parser.add_argument('--aggr', type=str, default=\"add\",\n",
    "#                     help='Aggregation method in GNN layer, only works in GraphSAGE')\n",
    "# parser.add_argument(\"--patience\", type=int, default=20, help=\"Patient epochs to wait before early stopping.\")\n",
    "# parser.add_argument('--factor', type=float, default=0.5, help='Factor for reducing learning rate scheduler')\n",
    "# parser.add_argument('--reprocess', action=\"store_true\", help='If true, reprocess the dataset')\n",
    "# parser.add_argument('--search', action=\"store_true\", help='If true, search hyper-parameters')\n",
    "# parser.add_argument(\"--pos_enc_dim\", type=int, default=6, help=\"Initial positional dim.\")\n",
    "# parser.add_argument(\"--pos_attr\", type=bool, default=False, help=\"Positional attributes.\")\n",
    "# parser.add_argument(\"--feature_augmentation\", type=bool, default=True, help=\"If true, feature augmentation.\")\n",
    "\n",
    "# Structure Augmentation\n",
    "parser = argparse.ArgumentParser(f'arguments for training and testing')\n",
    "parser.add_argument('--save_dir', type=str, default='./save', help='Base directory for saving information.')\n",
    "parser.add_argument('--seed', type=int, default=2, help='Random seed for reproducibility.') # 4 -> 93\n",
    "parser.add_argument('--dataset_name', type=str, default=\"COLLAB\",\n",
    "                    choices=(\"MUTAG\", \"PROTEINS\", \"PTC_MR\", \"IMDBBINARY\"), help='Name of dataset')\n",
    "parser.add_argument('--drop_prob', type=float, default=0.5,\n",
    "                    help='Probability of zeroing an activation in dropout layers.') # 0.5 -> 93\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='Batch size per GPU. Scales automatically when \\\n",
    "                        multiple GPUs are available.') # 32 -> 93\n",
    "parser.add_argument(\"--parallel\", action=\"store_true\",\n",
    "                    help=\"If true, use DataParallel for multi-gpu training\")\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='Number of worker.')\n",
    "parser.add_argument('--load_path', type=str, default=None, help='Path to load as a model checkpoint.')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='Learning rate.') # 0.001 ->93\n",
    "parser.add_argument('--l2_wd', type=float, default=3e-3, help='L2 weight decay.') # 3e-4 -> 93\n",
    "parser.add_argument('--num_epochs', type=int, default=100, help='Number of epochs.') # 350 -> 93\n",
    "parser.add_argument(\"--hidden_size\", type=int, default=128, help=\"Hidden size of the model\") # 128 -> 93\n",
    "parser.add_argument(\"--embedding_size\", type=int, default=16, help=\"Output size of the logistic model\") # 16 -> 93\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"KHopGNNConv\",\n",
    "                    choices=(\"KHopGNNConv\"), help=\"Base GNN model\")\n",
    "parser.add_argument(\"--K\", type=int, default=2, help=\"Number of hop to consider\") # 2 -> 93\n",
    "parser.add_argument(\"--num_layer\", type=int, default=2, help=\"Number of layer for feature encoder\") # 2 -> 93\n",
    "parser.add_argument(\"--JK\", type=str, default=\"sum\", choices=(\"sum\", \"max\", \"mean\", \"attention\", \"last\", \"concat\"),\n",
    "                    help=\"Jumping knowledge method\") # sum -> 93\n",
    "parser.add_argument(\"--residual\", default=True, action=\"store_true\", help=\"If true, use residual connection between each layer\")\n",
    "parser.add_argument(\"--virtual_node\", action=\"store_true\", default=False, \n",
    "                    help=\"If true, add virtual node information in each layer\")\n",
    "parser.add_argument(\"--eps\", type=float, default=0., help=\"Initial epsilon in GIN\")\n",
    "parser.add_argument(\"--train_eps\", action=\"store_true\", help=\"If true, the epsilon in GIN model is trainable\")\n",
    "parser.add_argument(\"--combine\", type=str, default=\"geometric\", choices=(\"attention\", \"geometric\"),\n",
    "                    help=\"Combine method in k-hop aggregation\") # geometric -> 93\n",
    "parser.add_argument(\"--pooling_method\", type=str, default=\"sum\", choices=(\"mean\", \"sum\", \"attention\"),\n",
    "                    help=\"Pooling method in graph classification\") # sum -> 93\n",
    "parser.add_argument('--norm_type', type=str, default=\"Batch\",\n",
    "                    choices=(\"Batch\", \"Layer\", \"Instance\", \"GraphSize\", \"Pair\"),\n",
    "                    help=\"Normalization method in model\") # Batch -> 93\n",
    "parser.add_argument('--aggr', type=str, default=\"add\",\n",
    "                    help='Aggregation method in GNN layer, only works in GraphSAGE')\n",
    "parser.add_argument(\"--patience\", type=int, default=20, help=\"Patient epochs to wait before early stopping.\")\n",
    "parser.add_argument('--factor', type=float, default=0.5, help='Factor for reducing learning rate scheduler')\n",
    "parser.add_argument('--reprocess', action=\"store_true\", help='If true, reprocess the dataset')\n",
    "parser.add_argument('--search', action=\"store_true\", help='If true, search hyper-parameters')\n",
    "parser.add_argument(\"--pos_enc_dim\", type=int, default=6, help=\"Initial positional dim.\") # 6 -> 93\n",
    "parser.add_argument(\"--pos_attr\", type=bool, default=False, help=\"Positional attributes.\")\n",
    "parser.add_argument(\"--feature_augmentation\", type=bool, default=False, help=\"If true, feature augmentation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab9b18e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b79b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.name = args.model_name + \"_\" + str(args.K) + \"_\" + str(args.search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7382c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging and devices\n",
    "args.save_dir = train_utils.get_save_dir(args.save_dir, args.name, type=args.dataset_name)\n",
    "log = train_utils.get_logger(args.save_dir, args.name)\n",
    "device, args.gpu_ids = train_utils.get_available_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf03f4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05.15.24 17:14:31] Using single-gpu training\n"
     ]
    }
   ],
   "source": [
    "if len(args.gpu_ids) > 1 and args.parallel:\n",
    "    log.info(f'Using multi-gpu training')\n",
    "    args.parallel = True\n",
    "    loader = DataListLoader\n",
    "    args.batch_size *= max(1, len(args.gpu_ids))\n",
    "else:\n",
    "    log.info(f'Using single-gpu training')\n",
    "    args.parallel = False\n",
    "    loader = DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "594ba3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05.15.24 17:14:31] Using random seed 2...\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "seed = args.seed\n",
    "log.info(f'Using random seed {seed}...')\n",
    "seed_everything(seed)\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e245fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_feature_transform(g):\n",
    "    return extract_edge_attributes(g, args.pos_enc_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779bf8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = str(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4650c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args):\n",
    "    layer = make_gnn_layer(args)\n",
    "    init_emb = LinearEncoder(args.input_size, args.hidden_size, pos_attr=args.pos_attr)\n",
    "    init_edge_attr_emb = LinearEdgeEncoder(args.edge_attr_size, args.hidden_size, edge_attr=True)\n",
    "    init_edge_attr_v2_emb = LinearEdgeEncoder(args.edge_attr_v2_size, args.hidden_size, edge_attr=False)\n",
    "    \n",
    "    GNNModel = make_GNN(args)\n",
    "    \n",
    "    gnn = GNNModel(\n",
    "        num_layer=args.num_layer,\n",
    "        gnn_layer=layer,\n",
    "        JK=args.JK,\n",
    "        norm_type=args.norm_type,\n",
    "        init_emb=init_emb,\n",
    "        init_edge_attr_emb=init_edge_attr_emb,\n",
    "        init_edge_attr_v2_emb=init_edge_attr_v2_emb,\n",
    "        residual=args.residual,\n",
    "        virtual_node=args.virtual_node,\n",
    "        drop_prob=args.drop_prob)\n",
    "\n",
    "    model = GraphClassification(embedding_model=gnn,\n",
    "                                pooling_method=args.pooling_method,\n",
    "                                output_size=args.output_size)\n",
    "    \n",
    "    model.reset_parameters()\n",
    "\n",
    "    if args.parallel:\n",
    "        model = DataParallel(model, args.gpu_ids)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc76b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projection(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Projection, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x) + self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42362252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vicreg_loss(embeddings1, embeddings2, lambda_var=25, lambda_cov=25, mu=1):\n",
    "    \"\"\"\n",
    "    Calculate the VICReg loss between two sets of embeddings with the correct handling of covariance differences.\n",
    "    \n",
    "    Args:\n",
    "    embeddings1, embeddings2 (torch.Tensor): Embeddings from two views, shape (batch_size, feature_dim).\n",
    "    lambda_var (float): Coefficient for the variance loss.\n",
    "    lambda_cov (float): Coefficient for the covariance loss.\n",
    "    mu (float): Coefficient for the invariance loss.\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: The total VICReg loss.\n",
    "    \"\"\"\n",
    "    # Invariance Loss\n",
    "    invariance_loss = F.mse_loss(embeddings1, embeddings2)\n",
    "\n",
    "    # Variance Loss\n",
    "    def variance_loss(embeddings1, embeddings2):\n",
    "        mean_embeddings1 = embeddings1.mean(dim=0)\n",
    "        mean_embeddings2 = embeddings2.mean(dim=0)\n",
    "        \n",
    "        std_dev1 = torch.sqrt((embeddings1 - mean_embeddings1).var(dim=0) + 1e-4)\n",
    "        std_dev2 = torch.sqrt((embeddings2 - mean_embeddings2).var(dim=0) + 1e-4)\n",
    "        \n",
    "        return torch.mean(torch.abs(F.relu(1 - std_dev1) - F.relu(1 - std_dev2)))\n",
    "\n",
    "    variance_loss_value = variance_loss(embeddings1, embeddings2)\n",
    "\n",
    "    # Covariance Loss\n",
    "    def covariance_loss(embeddings1, embeddings2):\n",
    "        batch_size, feature_dim = embeddings1.size()\n",
    "        \n",
    "        embeddings_centered1 = embeddings1 - embeddings1.mean(dim=0)\n",
    "        embeddings_centered2 = embeddings2 - embeddings2.mean(dim=0)\n",
    "        \n",
    "        covariance_matrix1 = torch.matmul(embeddings_centered1.T, embeddings_centered1) / (batch_size - 1)\n",
    "        covariance_matrix2 = torch.matmul(embeddings_centered2.T, embeddings_centered2) / (batch_size - 1)\n",
    "        \n",
    "        covariance_matrix1.fill_diagonal_(0)\n",
    "        covariance_matrix2.fill_diagonal_(0)\n",
    "        \n",
    "        cov_diff = torch.abs(covariance_matrix1.pow(2) - covariance_matrix2.pow(2))\n",
    "        return cov_diff.sum() / feature_dim\n",
    "\n",
    "    covariance_loss_value = covariance_loss(embeddings1, embeddings2)\n",
    "\n",
    "    total_loss = mu * invariance_loss + lambda_var * variance_loss_value + lambda_cov * covariance_loss_value\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bed468ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, model_1, model_2, mlp1, mlp2, aug1, aug2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model_1 = model_1\n",
    "        self.model_2 = model_2\n",
    "        self.mlp1 = mlp1\n",
    "        self.mlp2 = mlp2\n",
    "        self.aug1 = aug1\n",
    "        self.aug2 = aug2\n",
    "        \n",
    "    def get_embedding(self, data):\n",
    "        z, g = self.model_1(data)\n",
    "        z_pos, g_pos = self.model_2(data)\n",
    "        \n",
    "        z = self.mlp1(z)\n",
    "        g = self.mlp2(g)\n",
    "        \n",
    "        z_pos = self.mlp1(z_pos)\n",
    "        g_pos = self.mlp2(g_pos)\n",
    "\n",
    "        g = torch.cat((g, g_pos), 1)\n",
    "        z = torch.cat((z, z_pos), 1)\n",
    "\n",
    "        return g.detach(), z.detach()\n",
    "\n",
    "    def forward(self, data):\n",
    "        data1 = self.aug1(data.x, data.edge_index, data.y, data.pos, data.edge_attr,\n",
    "                          data.edge_attr_v2, data.batch, data.ptr)\n",
    "        data2 = self.aug2(data.x, data.edge_index, data.y, data.pos, data.edge_attr,\n",
    "                          data.edge_attr_v2, data.batch, data.ptr)\n",
    "        \n",
    "        # Structural features\n",
    "        z1, g1 = self.model_1(data1)\n",
    "        z2, g2 = self.model_1(data2)\n",
    "        \n",
    "        # Positional features\n",
    "        z1_pos, g1_pos = self.model_2(data1)\n",
    "        z2_pos, g2_pos = self.model_2(data2)\n",
    "        \n",
    "        h1, h2 = [self.mlp1(h) for h in [z1, z2]]\n",
    "        g1, g2 = [self.mlp2(g) for g in [g1, g2]]\n",
    "        \n",
    "        h1_pos, h2_pos = [self.mlp1(h_pos) for h_pos in [z1_pos, z2_pos]]\n",
    "        g1_pos, g2_pos = [self.mlp2(g_pos) for g_pos in [g1_pos, g2_pos]]\n",
    "        \n",
    "        h1 = torch.cat((h1, h1_pos), 1)\n",
    "        h2 = torch.cat((h2, h2_pos), 1)\n",
    "        g1 = torch.cat((g1, g1_pos), 1)\n",
    "        g2 = torch.cat((g2, g2_pos), 1)\n",
    "        \n",
    "        return h1, h2, g1, g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e3d931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder_model, dataloader, optimizer, device):\n",
    "    best = float(\"inf\")\n",
    "    cnt_wait = 0\n",
    "    best_t = 0\n",
    "    \n",
    "    loss_func = NTXentLoss(temperature=0.10)\n",
    "    \n",
    "    encoder_model.train()\n",
    "    epoch_loss = 0\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if data.x is None:\n",
    "            num_nodes = data.batch.size(0)\n",
    "            data.x = torch.ones((num_nodes, 1), dtype=torch.float32, device=data.batch.device)\n",
    "\n",
    "        h1, h2, g1, g2 = encoder_model(data)\n",
    "        \n",
    "        embeddings = torch.cat((g1, g2))\n",
    "        \n",
    "        # The same index corresponds to a positive pair\n",
    "        indices = torch.arange(0, g1.size(0), device=device)\n",
    "        labels = torch.cat((indices, indices))\n",
    "        \n",
    "        reg_loss = vicreg_loss(h1, h2, lambda_var=24, lambda_cov=24, mu=1)\n",
    "        loss = loss_func(embeddings, labels) + 0.005*reg_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            print(\"Epoch: {0}, Loss: {1:0.4f}\".format(epoch, epoch_loss))\n",
    "\n",
    "        if epoch_loss < best:\n",
    "            best = epoch_loss\n",
    "            best_t = epoch\n",
    "            cnt_wait = 0\n",
    "            torch.save(encoder_model.state_dict(), './pkl/best_model_'+ args.dataset_name + tag + '.pkl')\n",
    "        else:\n",
    "            cnt_wait += 1\n",
    "\n",
    "        if cnt_wait == args.patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "            \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b35fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder_model, dataloader, seeds, device):\n",
    "    encoder_model.eval()\n",
    "    x = []\n",
    "    y = []\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        if data.x is None:\n",
    "            num_nodes = data.batch.size(0)\n",
    "            data.x = torch.ones((num_nodes, 1), dtype=torch.float32, device=data.batch.device)\n",
    "        graph_embeds, node_embeds = encoder_model.get_embedding(data)\n",
    "        x.append(graph_embeds)\n",
    "        y.append(data.y)\n",
    "    x = torch.cat(x, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "\n",
    "    result = []\n",
    "    random.shuffle(seeds)\n",
    "    seeds = seeds.tolist()\n",
    "    for _ in np.arange(10):\n",
    "        random_seed = seeds.pop()\n",
    "        split = get_split(num_samples=x.size()[0], train_ratio=0.1, test_ratio=0.8, seed=random_seed)\n",
    "        result.append(LREvaluator()(x, y, split))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b4f4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/data_splits/\" + args.dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2abb9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices, train_test_indices = [], [], []\n",
    "for i in range(10):\n",
    "    train_filename = os.path.join(path, '10fold_idx', 'train_idx-{}.txt'.format(i + 1))\n",
    "    test_filename = os.path.join(path, '10fold_idx', 'test_idx-{}.txt'.format(i + 1))\n",
    "    train_indices.append(torch.from_numpy(np.loadtxt(train_filename, dtype=int)).to(torch.long))\n",
    "    test_indices.append(torch.from_numpy(np.loadtxt(test_filename, dtype=int)).to(torch.long))\n",
    "\n",
    "if args.feature_augmentation:\n",
    "    file_name = 'train_test_splits_feat.txt'\n",
    "else:\n",
    "    file_name = 'train_test_splits_struct.txt'\n",
    "    \n",
    "train_test_filename = os.path.join(path, '10fold_idx', file_name)\n",
    "train_test_indices.append(torch.from_numpy(np.loadtxt(train_test_filename, dtype=int)).to(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "172e785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root='./data/'+args.dataset_name, name=args.dataset_name, \n",
    "                    pre_transform=T.Compose([edge_feature_transform]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ba889e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum degree in the dataset\n",
    "max_degree = max([data.num_nodes for data in dataset])\n",
    "\n",
    "# Apply the OneHotDegree transform\n",
    "dataset.transform = T.OneHotDegree(max_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bd490eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = torch.unique(dataset.y)\n",
    "args.n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08278920",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.input_size = dataset.num_node_features\n",
    "args.pos_size = args.pos_enc_dim\n",
    "args.output_size = args.hidden_size\n",
    "args.edge_attr_size =  dataset.edge_attr.shape[1]\n",
    "args.edge_attr_v2_size =  dataset.edge_attr_v2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa5ef1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug1 = A.Identity()\n",
    "\n",
    "if args.feature_augmentation:\n",
    "    # Feature Augmentation\n",
    "    aug2 = A.RandomChoice([A.FeatureDropout(pf=0.1),\n",
    "                           A.FeatureMasking(pf=0.1),\n",
    "                           A.EdgeAttrMasking(pf=0.1)], 1)\n",
    "else:\n",
    "    # Structure Augmentation\n",
    "    aug2 = A.RandomChoice([A.RWSampling(num_seeds=1000, walk_length=10),\n",
    "                       A.NodeDropping(pn=0.1),\n",
    "                       A.EdgeRemoving(pe=0.1)], 1)\n",
    "\n",
    "model_1 = get_model(args)\n",
    "model_1.to(device)\n",
    "\n",
    "args.pos_attr = True\n",
    "args.input_size = args.pos_size\n",
    "model_2 = get_model(args)\n",
    "model_2.to(device)\n",
    "\n",
    "mlp1 = Projection(input_dim=args.hidden_size, output_dim=args.hidden_size)\n",
    "mlp2 = Projection(input_dim=args.hidden_size, output_dim=args.hidden_size)\n",
    "\n",
    "encoder_model = Encoder(model_1=model_1, model_2=model_2, mlp1=mlp1, mlp2=mlp2, aug1=aug1, aug2=aug2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1824b4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   1%|▎                          | 1/100 [00:13<21:49, 13.23s/it, loss=28.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   2%|▌                            | 2/100 [00:26<21:23, 13.10s/it, loss=14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   3%|▊                          | 3/100 [00:38<20:43, 12.82s/it, loss=10.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   4%|█                          | 4/100 [00:51<20:44, 12.96s/it, loss=8.77]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   5%|█▍                          | 5/100 [01:05<20:45, 13.11s/it, loss=7.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   6%|█▌                         | 6/100 [01:19<21:03, 13.44s/it, loss=6.07]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   7%|█▉                          | 7/100 [01:32<20:27, 13.20s/it, loss=6.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   8%|██▏                        | 8/100 [01:44<20:01, 13.06s/it, loss=6.14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   9%|██▍                        | 9/100 [01:57<19:30, 12.86s/it, loss=5.47]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  10%|██▌                       | 10/100 [02:10<19:21, 12.91s/it, loss=5.39]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  11%|██▊                       | 11/100 [02:23<19:09, 12.92s/it, loss=4.95]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  12%|███▏                       | 12/100 [02:36<18:54, 12.89s/it, loss=4.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  13%|███▍                      | 13/100 [02:49<18:44, 12.92s/it, loss=4.04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  14%|███▋                      | 14/100 [03:01<18:13, 12.72s/it, loss=4.56]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  15%|████                       | 15/100 [03:13<17:57, 12.67s/it, loss=3.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  16%|████▏                     | 16/100 [03:25<17:22, 12.41s/it, loss=3.88]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  17%|████▍                     | 17/100 [03:38<17:13, 12.46s/it, loss=3.52]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  18%|████▋                     | 18/100 [03:50<17:02, 12.47s/it, loss=3.57]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  19%|████▉                     | 19/100 [04:03<17:03, 12.64s/it, loss=3.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 20, Loss: 0.1477\n",
      "Epoch: 20, Loss: 0.4663\n",
      "Epoch: 20, Loss: 0.6459\n",
      "Epoch: 20, Loss: 0.8417\n",
      "Epoch: 20, Loss: 1.0859\n",
      "Epoch: 20, Loss: 1.2827\n",
      "Epoch: 20, Loss: 1.3929\n",
      "Epoch: 20, Loss: 1.5838\n",
      "Epoch: 20, Loss: 1.7436\n",
      "Epoch: 20, Loss: 1.8834\n",
      "Epoch: 20, Loss: 2.0066\n",
      "Epoch: 20, Loss: 2.1292\n",
      "Epoch: 20, Loss: 2.2544\n",
      "Epoch: 20, Loss: 2.3778\n",
      "Epoch: 20, Loss: 2.5188\n",
      "Epoch: 20, Loss: 2.6326\n",
      "Epoch: 20, Loss: 2.8924\n",
      "Epoch: 20, Loss: 3.0431\n",
      "Epoch: 20, Loss: 3.1561\n",
      "Epoch: 20, Loss: 3.3377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  20%|█████▏                    | 20/100 [04:16<16:43, 12.55s/it, loss=3.49]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 3.4895\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  21%|█████▍                    | 21/100 [04:28<16:31, 12.55s/it, loss=3.57]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  22%|█████▋                    | 22/100 [04:41<16:37, 12.79s/it, loss=3.49]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  23%|█████▉                    | 23/100 [04:54<16:25, 12.80s/it, loss=3.99]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  24%|██████▏                   | 24/100 [05:07<16:13, 12.81s/it, loss=3.75]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  25%|██████▌                   | 25/100 [05:19<15:46, 12.62s/it, loss=3.82]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  26%|██████▊                   | 26/100 [05:33<16:00, 12.98s/it, loss=3.35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  27%|███████                   | 27/100 [05:46<15:50, 13.03s/it, loss=3.35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  28%|███████▌                   | 28/100 [06:01<16:24, 13.67s/it, loss=3.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  29%|███████▌                  | 29/100 [06:14<15:46, 13.34s/it, loss=3.29]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  30%|███████▊                  | 30/100 [06:26<15:14, 13.07s/it, loss=3.26]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  31%|████████                  | 31/100 [06:39<14:55, 12.98s/it, loss=3.48]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  32%|████████▎                 | 32/100 [06:52<14:48, 13.06s/it, loss=3.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  33%|████████▌                 | 33/100 [07:05<14:21, 12.86s/it, loss=3.51]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  34%|████████▊                 | 34/100 [07:17<13:57, 12.69s/it, loss=3.83]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  35%|█████████                 | 35/100 [07:30<13:53, 12.83s/it, loss=3.21]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  36%|█████████▋                 | 36/100 [07:43<13:38, 12.80s/it, loss=3.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  37%|█████████▌                | 37/100 [07:56<13:21, 12.72s/it, loss=3.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  38%|█████████▉                | 38/100 [08:08<12:57, 12.54s/it, loss=3.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  39%|██████████▏               | 39/100 [08:20<12:43, 12.51s/it, loss=3.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 40, Loss: 0.1632\n",
      "Epoch: 40, Loss: 0.4969\n",
      "Epoch: 40, Loss: 0.6512\n",
      "Epoch: 40, Loss: 0.8241\n",
      "Epoch: 40, Loss: 1.0494\n",
      "Epoch: 40, Loss: 1.1830\n",
      "Epoch: 40, Loss: 1.3394\n",
      "Epoch: 40, Loss: 1.5723\n",
      "Epoch: 40, Loss: 1.7169\n",
      "Epoch: 40, Loss: 1.8813\n",
      "Epoch: 40, Loss: 2.0701\n",
      "Epoch: 40, Loss: 2.2687\n",
      "Epoch: 40, Loss: 2.4364\n",
      "Epoch: 40, Loss: 2.5968\n",
      "Epoch: 40, Loss: 2.7483\n",
      "Epoch: 40, Loss: 2.8747\n",
      "Epoch: 40, Loss: 3.1136\n",
      "Epoch: 40, Loss: 3.3035\n",
      "Epoch: 40, Loss: 3.4405\n",
      "Epoch: 40, Loss: 3.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  40%|██████████▍               | 40/100 [08:32<12:15, 12.25s/it, loss=3.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Loss: 3.7250\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  41%|██████████▋               | 41/100 [08:44<12:07, 12.33s/it, loss=3.19]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  42%|██████████▉               | 42/100 [08:57<11:58, 12.39s/it, loss=3.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  43%|███████████▏              | 43/100 [09:08<11:24, 12.02s/it, loss=3.47]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  44%|███████████▍              | 44/100 [09:20<11:19, 12.14s/it, loss=3.18]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  45%|████████████▏              | 45/100 [09:32<10:52, 11.87s/it, loss=3.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  46%|███████████▉              | 46/100 [09:43<10:27, 11.61s/it, loss=3.45]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  47%|████████████▏             | 47/100 [09:55<10:24, 11.79s/it, loss=3.35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  48%|████████████▍             | 48/100 [10:07<10:16, 11.86s/it, loss=3.34]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  49%|█████████████▏             | 49/100 [10:19<10:07, 11.91s/it, loss=3.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  50%|█████████████             | 50/100 [10:31<09:55, 11.92s/it, loss=3.14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  51%|█████████████▎            | 51/100 [10:42<09:39, 11.82s/it, loss=3.07]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  52%|██████████████             | 52/100 [10:54<09:26, 11.81s/it, loss=3.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  53%|█████████████▊            | 53/100 [11:06<09:14, 11.79s/it, loss=3.45]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  54%|██████████████            | 54/100 [11:17<08:57, 11.69s/it, loss=3.79]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  55%|██████████████▊            | 55/100 [11:29<08:49, 11.76s/it, loss=3.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  56%|██████████████▌           | 56/100 [11:41<08:41, 11.86s/it, loss=3.52]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  57%|██████████████▊           | 57/100 [11:53<08:29, 11.84s/it, loss=3.57]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  58%|███████████████           | 58/100 [12:04<08:09, 11.66s/it, loss=3.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  59%|███████████████▎          | 59/100 [12:16<07:53, 11.55s/it, loss=3.79]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 60, Loss: 0.1557\n",
      "Epoch: 60, Loss: 0.3975\n",
      "Epoch: 60, Loss: 0.5411\n",
      "Epoch: 60, Loss: 0.6880\n",
      "Epoch: 60, Loss: 0.9485\n",
      "Epoch: 60, Loss: 1.1092\n",
      "Epoch: 60, Loss: 1.3306\n",
      "Epoch: 60, Loss: 1.5925\n",
      "Epoch: 60, Loss: 1.8374\n",
      "Epoch: 60, Loss: 1.9645\n",
      "Epoch: 60, Loss: 2.1259\n",
      "Epoch: 60, Loss: 2.3426\n",
      "Epoch: 60, Loss: 2.5367\n",
      "Epoch: 60, Loss: 2.7201\n",
      "Epoch: 60, Loss: 2.9546\n",
      "Epoch: 60, Loss: 3.1577\n",
      "Epoch: 60, Loss: 3.4906\n",
      "Epoch: 60, Loss: 3.7213\n",
      "Epoch: 60, Loss: 3.8764\n",
      "Epoch: 60, Loss: 4.0395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  60%|███████████████▌          | 60/100 [12:27<07:33, 11.34s/it, loss=4.29]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Loss: 4.2919\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  61%|███████████████▊          | 61/100 [12:39<07:36, 11.70s/it, loss=3.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  62%|████████████████          | 62/100 [12:50<07:18, 11.54s/it, loss=3.91]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  63%|████████████████▍         | 63/100 [13:02<07:05, 11.50s/it, loss=3.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  64%|████████████████▋         | 64/100 [13:13<06:52, 11.46s/it, loss=4.02]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  65%|████████████████▉         | 65/100 [13:24<06:36, 11.33s/it, loss=4.07]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  66%|█████████████████▏        | 66/100 [13:35<06:25, 11.34s/it, loss=3.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  67%|█████████████████▍        | 67/100 [13:47<06:19, 11.50s/it, loss=3.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  68%|█████████████████▋        | 68/100 [13:58<06:01, 11.30s/it, loss=3.51]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  69%|██████████████████▋        | 69/100 [14:10<05:58, 11.58s/it, loss=3.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  70%|██████████████████▏       | 70/100 [14:22<05:44, 11.48s/it, loss=3.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  71%|██████████████████▍       | 71/100 [14:33<05:33, 11.51s/it, loss=2.96]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  72%|██████████████████▋       | 72/100 [14:45<05:22, 11.53s/it, loss=2.97]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  73%|██████████████████▉       | 73/100 [14:56<05:11, 11.54s/it, loss=3.05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  74%|███████████████████▏      | 74/100 [15:09<05:06, 11.81s/it, loss=3.12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  75%|████████████████████▎      | 75/100 [15:22<05:07, 12.31s/it, loss=3.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  76%|███████████████████▊      | 76/100 [15:33<04:45, 11.88s/it, loss=3.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  77%|████████████████████      | 77/100 [15:45<04:30, 11.78s/it, loss=3.34]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  78%|████████████████████▎     | 78/100 [15:56<04:14, 11.55s/it, loss=3.89]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  79%|████████████████████▌     | 79/100 [16:07<04:03, 11.58s/it, loss=4.12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 80, Loss: 0.1906\n",
      "Epoch: 80, Loss: 0.4731\n",
      "Epoch: 80, Loss: 0.7016\n",
      "Epoch: 80, Loss: 0.8845\n",
      "Epoch: 80, Loss: 1.1903\n",
      "Epoch: 80, Loss: 1.4075\n",
      "Epoch: 80, Loss: 1.5759\n",
      "Epoch: 80, Loss: 1.7573\n",
      "Epoch: 80, Loss: 1.9189\n",
      "Epoch: 80, Loss: 2.0614\n",
      "Epoch: 80, Loss: 2.2154\n",
      "Epoch: 80, Loss: 2.3807\n",
      "Epoch: 80, Loss: 2.5331\n",
      "Epoch: 80, Loss: 2.6879\n",
      "Epoch: 80, Loss: 2.8682\n",
      "Epoch: 80, Loss: 3.0640\n",
      "Epoch: 80, Loss: 3.3219\n",
      "Epoch: 80, Loss: 3.5284\n",
      "Epoch: 80, Loss: 3.7420\n",
      "Epoch: 80, Loss: 3.9208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  80%|████████████████████▊     | 80/100 [16:19<03:49, 11.50s/it, loss=4.08]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Loss: 4.0807\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  81%|█████████████████████     | 81/100 [16:31<03:41, 11.65s/it, loss=4.33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  82%|█████████████████████▎    | 82/100 [16:43<03:32, 11.83s/it, loss=4.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  83%|█████████████████████▌    | 83/100 [16:57<03:31, 12.44s/it, loss=3.69]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  84%|█████████████████████▊    | 84/100 [17:09<03:16, 12.27s/it, loss=3.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  85%|██████████████████████    | 85/100 [17:21<03:03, 12.21s/it, loss=3.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  86%|██████████████████████▎   | 86/100 [17:34<02:56, 12.60s/it, loss=3.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  87%|██████████████████████▌   | 87/100 [17:46<02:40, 12.38s/it, loss=3.39]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  88%|██████████████████████▉   | 88/100 [17:59<02:28, 12.40s/it, loss=3.49]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  89%|███████████████████████▏  | 89/100 [18:11<02:15, 12.35s/it, loss=3.45]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  90%|███████████████████████▍  | 90/100 [18:22<02:01, 12.16s/it, loss=3.43]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  91%|███████████████████████▋  | 91/100 [18:34<01:48, 12.06s/it, loss=3.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  92%|███████████████████████▉  | 92/100 [18:46<01:35, 11.88s/it, loss=3.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  93%|████████████████████████▏ | 93/100 [18:58<01:24, 12.13s/it, loss=3.18]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  94%|████████████████████████▍ | 94/100 [19:12<01:15, 12.57s/it, loss=3.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  95%|████████████████████████▋ | 95/100 [19:25<01:04, 12.83s/it, loss=3.04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  96%|████████████████████████▉ | 96/100 [19:37<00:49, 12.48s/it, loss=3.22]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  97%|█████████████████████████▏| 97/100 [19:49<00:36, 12.16s/it, loss=3.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  98%|█████████████████████████▍| 98/100 [20:00<00:23, 12.00s/it, loss=3.23]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  99%|█████████████████████████▋| 99/100 [20:11<00:11, 11.78s/it, loss=3.19]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 100, Loss: 0.1325\n",
      "Epoch: 100, Loss: 0.3592\n",
      "Epoch: 100, Loss: 0.4958\n",
      "Epoch: 100, Loss: 0.6571\n",
      "Epoch: 100, Loss: 0.9247\n",
      "Epoch: 100, Loss: 1.0702\n",
      "Epoch: 100, Loss: 1.2044\n",
      "Epoch: 100, Loss: 1.3528\n",
      "Epoch: 100, Loss: 1.5015\n",
      "Epoch: 100, Loss: 1.6499\n",
      "Epoch: 100, Loss: 1.8329\n",
      "Epoch: 100, Loss: 2.0070\n",
      "Epoch: 100, Loss: 2.1455\n",
      "Epoch: 100, Loss: 2.2925\n",
      "Epoch: 100, Loss: 2.4604\n",
      "Epoch: 100, Loss: 2.6255\n",
      "Epoch: 100, Loss: 2.8785\n",
      "Epoch: 100, Loss: 3.0619\n",
      "Epoch: 100, Loss: 3.2015\n",
      "Epoch: 100, Loss: 3.3546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T): 100%|█████████████████████████| 100/100 [20:22<00:00, 12.23s/it, loss=3.53]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 3.5297\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(encoder_model.parameters(), lr=args.lr, weight_decay=args.l2_wd)\n",
    "dataloader = DataLoader(dataset, batch_size=args.batch_size)\n",
    "with tqdm(total=100, desc='(T)') as pbar:\n",
    "    for epoch in range(1, 101):\n",
    "        loss = train(encoder_model, dataloader, optimizer, device)\n",
    "        pbar.set_postfix({'loss': loss})\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02668570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|███████████| 5000/5000 [00:02<00:00, best test F1Mi=0.764, F1Ma=0.73]\n",
      "(LR): 100%|██████████| 5000/5000 [00:02<00:00, best test F1Mi=0.752, F1Ma=0.722]\n",
      "(LR): 100%|██████████| 5000/5000 [00:02<00:00, best test F1Mi=0.752, F1Ma=0.722]\n",
      "(LR): 100%|██████████| 5000/5000 [00:02<00:00, best test F1Mi=0.774, F1Ma=0.753]\n",
      "(LR): 100%|██████████| 5000/5000 [00:02<00:00, best test F1Mi=0.752, F1Ma=0.734]\n",
      "(LR): 100%|██████████| 5000/5000 [00:02<00:00, best test F1Mi=0.752, F1Ma=0.722]\n",
      "(LR): 100%|███████████| 5000/5000 [00:02<00:00, best test F1Mi=0.76, F1Ma=0.729]\n",
      "(LR): 100%|███████████| 5000/5000 [00:02<00:00, best test F1Mi=0.75, F1Ma=0.731]\n",
      "(LR): 100%|███████████| 5000/5000 [00:02<00:00, best test F1Mi=0.768, F1Ma=0.75]\n",
      "(LR): 100%|██████████| 5000/5000 [00:02<00:00, best test F1Mi=0.758, F1Ma=0.724]\n"
     ]
    }
   ],
   "source": [
    "test_result = test(encoder_model, dataloader, train_test_indices[0], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cd98e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_f1_values = [entry['micro_f1']*100 for entry in test_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a74c706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc mean = 75.8200 ± 0.7769\n"
     ]
    }
   ],
   "source": [
    "np_micro_f1_values = np.array(micro_f1_values)\n",
    "micro_f1_mean = np.mean(np_micro_f1_values)\n",
    "micro_f1_std = np.std(np_micro_f1_values)\n",
    "\n",
    "print(f'test acc mean = {micro_f1_mean:.4f} ± {micro_f1_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f65f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
