{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d57062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import time\n",
    "from itertools import product\n",
    "from json import dumps\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.loader import DataListLoader, DataLoader\n",
    "from torch_geometric.nn import DataParallel\n",
    "from torch_geometric.seed import seed_everything\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data import DataLoader, Data\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pytorch_metric_learning.losses import NTXentLoss, VICRegLoss\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "import train_utils\n",
    "from data_utils import extract_edge_attributes\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from layers.input_encoder import LinearEncoder, LinearEdgeEncoder\n",
    "from layers.layer_utils import make_gnn_layer\n",
    "from models.GraphClassification import GraphClassification\n",
    "from models.model_utils import make_GNN\n",
    "\n",
    "import GCL.losses as L\n",
    "import GCL.augmentors as A\n",
    "from GCL.eval import get_split, SVMEvaluator, LREvaluator\n",
    "from GCL.models import DualBranchContrast\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233c2b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--feature_augmentation'], dest='feature_augmentation', nargs=None, const=None, default=True, type=<class 'bool'>, choices=None, required=False, help='If true, feature augmentation.', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Augmentation\n",
    "parser = argparse.ArgumentParser(f'arguments for training and testing')\n",
    "parser.add_argument('--save_dir', type=str, default='./save', help='Base directory for saving information.')\n",
    "parser.add_argument('--seed', type=int, default=2, help='Random seed for reproducibility.')\n",
    "parser.add_argument('--dataset_name', type=str, default=\"PROTEINS\",\n",
    "                    choices=(\"MUTAG\", \"PROTEINS\", \"PTC_MR\", \"IMDBBINARY\"), help='Name of dataset')\n",
    "parser.add_argument('--drop_prob', type=float, default=0.6,\n",
    "                    help='Probability of zeroing an activation in dropout layers.') \n",
    "parser.add_argument('--batch_size', type=int, default=32, help='Batch size per GPU. Scales automatically when \\\n",
    "                        multiple GPUs are available.')\n",
    "parser.add_argument(\"--parallel\", action=\"store_true\",\n",
    "                    help=\"If true, use DataParallel for multi-gpu training\")\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='Number of worker.')\n",
    "parser.add_argument('--load_path', type=str, default=None, help='Path to load as a model checkpoint.')\n",
    "parser.add_argument('--lr', type=float, default=0.005, help='Learning rate.')\n",
    "parser.add_argument('--l2_wd', type=float, default=3e-4, help='L2 weight decay.')\n",
    "parser.add_argument('--num_epochs', type=int, default=100, help='Number of epochs.')\n",
    "parser.add_argument(\"--hidden_size\", type=int, default=128, help=\"Hidden size of the model\")\n",
    "parser.add_argument(\"--embedding_size\", type=int, default=16, help=\"Output size of the logistic model\")\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"KHopGNNConv\",\n",
    "                    choices=(\"KHopGNNConv\"), help=\"Base GNN model\")\n",
    "parser.add_argument(\"--K\", type=int, default=2, help=\"Number of hop to consider\")\n",
    "parser.add_argument(\"--num_layer\", type=int, default=2, help=\"Number of layer for feature encoder\")\n",
    "parser.add_argument(\"--JK\", type=str, default=\"sum\", choices=(\"sum\", \"max\", \"mean\", \"attention\", \"last\", \"concat\"),\n",
    "                    help=\"Jumping knowledge method\")\n",
    "parser.add_argument(\"--residual\", default=True, action=\"store_true\", help=\"If true, use residual connection between each layer\")\n",
    "parser.add_argument(\"--virtual_node\", action=\"store_true\", default=False, \n",
    "                    help=\"If true, add virtual node information in each layer\")\n",
    "parser.add_argument(\"--eps\", type=float, default=0., help=\"Initial epsilon in GIN\")\n",
    "parser.add_argument(\"--train_eps\", action=\"store_true\", help=\"If true, the epsilon in GIN model is trainable\")\n",
    "parser.add_argument(\"--combine\", type=str, default=\"geometric\", choices=(\"attention\", \"geometric\"),\n",
    "                    help=\"Combine method in k-hop aggregation\")\n",
    "parser.add_argument(\"--pooling_method\", type=str, default=\"sum\", choices=(\"mean\", \"sum\", \"attention\"),\n",
    "                    help=\"Pooling method in graph classification\")\n",
    "parser.add_argument('--norm_type', type=str, default=\"Batch\",\n",
    "                    choices=(\"Batch\", \"Layer\", \"Instance\", \"GraphSize\", \"Pair\"),\n",
    "                    help=\"Normalization method in model\")\n",
    "parser.add_argument('--aggr', type=str, default=\"add\",\n",
    "                    help='Aggregation method in GNN layer, only works in GraphSAGE')\n",
    "parser.add_argument(\"--patience\", type=int, default=20, help=\"Patient epochs to wait before early stopping.\")\n",
    "parser.add_argument('--factor', type=float, default=0.5, help='Factor for reducing learning rate scheduler')\n",
    "parser.add_argument('--reprocess', action=\"store_true\", help='If true, reprocess the dataset')\n",
    "parser.add_argument('--search', action=\"store_true\", help='If true, search hyper-parameters')\n",
    "parser.add_argument(\"--pos_enc_dim\", type=int, default=6, help=\"Initial positional dim.\")\n",
    "parser.add_argument(\"--pos_attr\", type=bool, default=False, help=\"Positional attributes.\")\n",
    "parser.add_argument(\"--feature_augmentation\", type=bool, default=True, help=\"If true, feature augmentation.\")\n",
    "\n",
    "# Structure Augmentation\n",
    "# parser = argparse.ArgumentParser(f'arguments for training and testing')\n",
    "# parser.add_argument('--save_dir', type=str, default='./save', help='Base directory for saving information.')\n",
    "# parser.add_argument('--seed', type=int, default=2, help='Random seed for reproducibility.') # 4 -> 93\n",
    "# parser.add_argument('--dataset_name', type=str, default=\"PROTEINS\",\n",
    "#                     choices=(\"MUTAG\", \"PROTEINS\", \"PTC_MR\", \"IMDBBINARY\"), help='Name of dataset')\n",
    "# parser.add_argument('--drop_prob', type=float, default=0.5,\n",
    "#                     help='Probability of zeroing an activation in dropout layers.') # 0.5 -> 93\n",
    "# parser.add_argument('--batch_size', type=int, default=32, help='Batch size per GPU. Scales automatically when \\\n",
    "#                         multiple GPUs are available.') # 32 -> 93\n",
    "# parser.add_argument(\"--parallel\", action=\"store_true\",\n",
    "#                     help=\"If true, use DataParallel for multi-gpu training\")\n",
    "# parser.add_argument('--num_workers', type=int, default=0, help='Number of worker.')\n",
    "# parser.add_argument('--load_path', type=str, default=None, help='Path to load as a model checkpoint.')\n",
    "# parser.add_argument('--lr', type=float, default=0.001, help='Learning rate.') # 0.001 ->93\n",
    "# parser.add_argument('--l2_wd', type=float, default=3e-4, help='L2 weight decay.') # 3e-4 -> 93\n",
    "# parser.add_argument('--num_epochs', type=int, default=100, help='Number of epochs.') # 350 -> 93\n",
    "# parser.add_argument(\"--hidden_size\", type=int, default=128, help=\"Hidden size of the model\") # 128 -> 93\n",
    "# parser.add_argument(\"--embedding_size\", type=int, default=16, help=\"Output size of the logistic model\") # 16 -> 93\n",
    "# parser.add_argument(\"--model_name\", type=str, default=\"KHopGNNConv\",\n",
    "#                     choices=(\"KHopGNNConv\"), help=\"Base GNN model\")\n",
    "# parser.add_argument(\"--K\", type=int, default=2, help=\"Number of hop to consider\") # 2 -> 93\n",
    "# parser.add_argument(\"--num_layer\", type=int, default=2, help=\"Number of layer for feature encoder\") # 2 -> 93\n",
    "# parser.add_argument(\"--JK\", type=str, default=\"sum\", choices=(\"sum\", \"max\", \"mean\", \"attention\", \"last\", \"concat\"),\n",
    "#                     help=\"Jumping knowledge method\") # sum -> 93\n",
    "# parser.add_argument(\"--residual\", default=True, action=\"store_true\", help=\"If true, use residual connection between each layer\")\n",
    "# parser.add_argument(\"--virtual_node\", action=\"store_true\", default=False, \n",
    "#                     help=\"If true, add virtual node information in each layer\")\n",
    "# parser.add_argument(\"--eps\", type=float, default=0., help=\"Initial epsilon in GIN\")\n",
    "# parser.add_argument(\"--train_eps\", action=\"store_true\", help=\"If true, the epsilon in GIN model is trainable\")\n",
    "# parser.add_argument(\"--combine\", type=str, default=\"geometric\", choices=(\"attention\", \"geometric\"),\n",
    "#                     help=\"Combine method in k-hop aggregation\") # geometric -> 93\n",
    "# parser.add_argument(\"--pooling_method\", type=str, default=\"sum\", choices=(\"mean\", \"sum\", \"attention\"),\n",
    "#                     help=\"Pooling method in graph classification\") # sum -> 93\n",
    "# parser.add_argument('--norm_type', type=str, default=\"Batch\",\n",
    "#                     choices=(\"Batch\", \"Layer\", \"Instance\", \"GraphSize\", \"Pair\"),\n",
    "#                     help=\"Normalization method in model\") # Batch -> 93\n",
    "# parser.add_argument('--aggr', type=str, default=\"add\",\n",
    "#                     help='Aggregation method in GNN layer, only works in GraphSAGE')\n",
    "# parser.add_argument(\"--patience\", type=int, default=20, help=\"Patient epochs to wait before early stopping.\")\n",
    "# parser.add_argument('--factor', type=float, default=0.5, help='Factor for reducing learning rate scheduler')\n",
    "# parser.add_argument('--reprocess', action=\"store_true\", help='If true, reprocess the dataset')\n",
    "# parser.add_argument('--search', action=\"store_true\", help='If true, search hyper-parameters')\n",
    "# parser.add_argument(\"--pos_enc_dim\", type=int, default=6, help=\"Initial positional dim.\") # 6 -> 93\n",
    "# parser.add_argument(\"--pos_attr\", type=bool, default=False, help=\"Positional attributes.\")\n",
    "# parser.add_argument(\"--feature_augmentation\", type=bool, default=False, help=\"If true, feature augmentation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5f0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef97113",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.name = args.model_name + \"_\" + str(args.K) + \"_\" + str(args.search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72922be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging and devices\n",
    "args.save_dir = train_utils.get_save_dir(args.save_dir, args.name, type=args.dataset_name)\n",
    "log = train_utils.get_logger(args.save_dir, args.name)\n",
    "device, args.gpu_ids = train_utils.get_available_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b726781e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05.12.24 21:08:54] Using single-gpu training\n"
     ]
    }
   ],
   "source": [
    "if len(args.gpu_ids) > 1 and args.parallel:\n",
    "    log.info(f'Using multi-gpu training')\n",
    "    args.parallel = True\n",
    "    loader = DataListLoader\n",
    "    args.batch_size *= max(1, len(args.gpu_ids))\n",
    "else:\n",
    "    log.info(f'Using single-gpu training')\n",
    "    args.parallel = False\n",
    "    loader = DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdc6b34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05.12.24 21:08:54] Using random seed 2...\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "seed = args.seed\n",
    "log.info(f'Using random seed {seed}...')\n",
    "seed_everything(seed)\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e549e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_feature_transform(g):\n",
    "    return extract_edge_attributes(g, args.pos_enc_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf5865f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = str(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d8a8cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args):\n",
    "    layer = make_gnn_layer(args)\n",
    "    init_emb = LinearEncoder(args.input_size, args.hidden_size, pos_attr=args.pos_attr)\n",
    "    init_edge_attr_emb = LinearEdgeEncoder(args.edge_attr_size, args.hidden_size, edge_attr=True)\n",
    "    init_edge_attr_v2_emb = LinearEdgeEncoder(args.edge_attr_v2_size, args.hidden_size, edge_attr=False)\n",
    "    \n",
    "    GNNModel = make_GNN(args)\n",
    "    \n",
    "    gnn = GNNModel(\n",
    "        num_layer=args.num_layer,\n",
    "        gnn_layer=layer,\n",
    "        JK=args.JK,\n",
    "        norm_type=args.norm_type,\n",
    "        init_emb=init_emb,\n",
    "        init_edge_attr_emb=init_edge_attr_emb,\n",
    "        init_edge_attr_v2_emb=init_edge_attr_v2_emb,\n",
    "        residual=args.residual,\n",
    "        virtual_node=args.virtual_node,\n",
    "        drop_prob=args.drop_prob)\n",
    "\n",
    "    model = GraphClassification(embedding_model=gnn,\n",
    "                                pooling_method=args.pooling_method,\n",
    "                                output_size=args.output_size)\n",
    "    \n",
    "    model.reset_parameters()\n",
    "\n",
    "    if args.parallel:\n",
    "        model = DataParallel(model, args.gpu_ids)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "709eae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projection(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Projection, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x) + self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27924842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vicreg_loss(embeddings1, embeddings2, lambda_var=25, lambda_cov=25, mu=1):\n",
    "    \"\"\"\n",
    "    Calculate the VICReg loss between two sets of embeddings with the correct handling of covariance differences.\n",
    "    \n",
    "    Args:\n",
    "    embeddings1, embeddings2 (torch.Tensor): Embeddings from two views, shape (batch_size, feature_dim).\n",
    "    lambda_var (float): Coefficient for the variance loss.\n",
    "    lambda_cov (float): Coefficient for the covariance loss.\n",
    "    mu (float): Coefficient for the invariance loss.\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: The total VICReg loss.\n",
    "    \"\"\"\n",
    "    # Invariance Loss\n",
    "    invariance_loss = F.mse_loss(embeddings1, embeddings2)\n",
    "\n",
    "    # Variance Loss\n",
    "    def variance_loss(embeddings1, embeddings2):\n",
    "        mean_embeddings1 = embeddings1.mean(dim=0)\n",
    "        mean_embeddings2 = embeddings2.mean(dim=0)\n",
    "        \n",
    "        std_dev1 = torch.sqrt((embeddings1 - mean_embeddings1).var(dim=0) + 1e-4)\n",
    "        std_dev2 = torch.sqrt((embeddings2 - mean_embeddings2).var(dim=0) + 1e-4)\n",
    "        \n",
    "        return torch.mean(torch.abs(F.relu(1 - std_dev1) - F.relu(1 - std_dev2)))\n",
    "\n",
    "    variance_loss_value = variance_loss(embeddings1, embeddings2)\n",
    "\n",
    "    # Covariance Loss\n",
    "    def covariance_loss(embeddings1, embeddings2):\n",
    "        batch_size, feature_dim = embeddings1.size()\n",
    "        \n",
    "        embeddings_centered1 = embeddings1 - embeddings1.mean(dim=0)\n",
    "        embeddings_centered2 = embeddings2 - embeddings2.mean(dim=0)\n",
    "        \n",
    "        covariance_matrix1 = torch.matmul(embeddings_centered1.T, embeddings_centered1) / (batch_size - 1)\n",
    "        covariance_matrix2 = torch.matmul(embeddings_centered2.T, embeddings_centered2) / (batch_size - 1)\n",
    "        \n",
    "        covariance_matrix1.fill_diagonal_(0)\n",
    "        covariance_matrix2.fill_diagonal_(0)\n",
    "        \n",
    "        cov_diff = torch.abs(covariance_matrix1.pow(2) - covariance_matrix2.pow(2))\n",
    "        return cov_diff.sum() / feature_dim\n",
    "\n",
    "    covariance_loss_value = covariance_loss(embeddings1, embeddings2)\n",
    "\n",
    "    total_loss = mu * invariance_loss + lambda_var * variance_loss_value + lambda_cov * covariance_loss_value\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fafab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, model_1, model_2, mlp1, mlp2, aug1, aug2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model_1 = model_1\n",
    "        self.model_2 = model_2\n",
    "        self.mlp1 = mlp1\n",
    "        self.mlp2 = mlp2\n",
    "        self.aug1 = aug1\n",
    "        self.aug2 = aug2\n",
    "        \n",
    "    def get_embedding(self, data):\n",
    "        z, g = self.model_1(data)\n",
    "        z_pos, g_pos = self.model_2(data)\n",
    "        \n",
    "        z = self.mlp1(z)\n",
    "        g = self.mlp2(g)\n",
    "        \n",
    "        z_pos = self.mlp1(z_pos)\n",
    "        g_pos = self.mlp2(g_pos)\n",
    "\n",
    "        g = torch.cat((g, g_pos), 1)\n",
    "        z = torch.cat((z, z_pos), 1)\n",
    "\n",
    "        return g.detach(), z.detach()\n",
    "\n",
    "    def forward(self, data):\n",
    "        data1 = self.aug1(data.x, data.edge_index, data.y, data.pos, data.edge_attr,\n",
    "                          data.edge_attr_v2, data.batch, data.ptr)\n",
    "        data2 = self.aug2(data.x, data.edge_index, data.y, data.pos, data.edge_attr,\n",
    "                          data.edge_attr_v2, data.batch, data.ptr)\n",
    "        \n",
    "        # Structural features\n",
    "        z1, g1 = self.model_1(data1)\n",
    "        z2, g2 = self.model_1(data2)\n",
    "        \n",
    "        # Positional features\n",
    "        z1_pos, g1_pos = self.model_2(data1)\n",
    "        z2_pos, g2_pos = self.model_2(data2)\n",
    "        \n",
    "        h1, h2 = [self.mlp1(h) for h in [z1, z2]]\n",
    "        g1, g2 = [self.mlp2(g) for g in [g1, g2]]\n",
    "        \n",
    "        h1_pos, h2_pos = [self.mlp1(h_pos) for h_pos in [z1_pos, z2_pos]]\n",
    "        g1_pos, g2_pos = [self.mlp2(g_pos) for g_pos in [g1_pos, g2_pos]]\n",
    "        \n",
    "        h1 = torch.cat((h1, h1_pos), 1)\n",
    "        h2 = torch.cat((h2, h2_pos), 1)\n",
    "        g1 = torch.cat((g1, g1_pos), 1)\n",
    "        g2 = torch.cat((g2, g2_pos), 1)\n",
    "        \n",
    "        return h1, h2, g1, g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ecdbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder_model, dataloader, optimizer, device):\n",
    "    best = float(\"inf\")\n",
    "    cnt_wait = 0\n",
    "    best_t = 0\n",
    "    \n",
    "    loss_func = NTXentLoss(temperature=0.10)\n",
    "    \n",
    "    encoder_model.train()\n",
    "    epoch_loss = 0\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if data.x is None:\n",
    "            num_nodes = data.batch.size(0)\n",
    "            data.x = torch.ones((num_nodes, 1), dtype=torch.float32, device=data.batch.device)\n",
    "\n",
    "        h1, h2, g1, g2 = encoder_model(data)\n",
    "        \n",
    "        embeddings = torch.cat((g1, g2))\n",
    "        \n",
    "        # The same index corresponds to a positive pair\n",
    "        indices = torch.arange(0, g1.size(0), device=device)\n",
    "        labels = torch.cat((indices, indices))\n",
    "        \n",
    "        reg_loss = vicreg_loss(h1, h2, lambda_var=24, lambda_cov=24, mu=1)\n",
    "        loss = loss_func(embeddings, labels) + 0.005*reg_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            print(\"Epoch: {0}, Loss: {1:0.4f}\".format(epoch, epoch_loss))\n",
    "\n",
    "        if epoch_loss < best:\n",
    "            best = epoch_loss\n",
    "            best_t = epoch\n",
    "            cnt_wait = 0\n",
    "            torch.save(encoder_model.state_dict(), './pkl/best_model_'+ args.dataset_name + tag + '.pkl')\n",
    "        else:\n",
    "            cnt_wait += 1\n",
    "\n",
    "        if cnt_wait == args.patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "            \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ff75192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder_model, dataloader, seeds, device):\n",
    "    encoder_model.eval()\n",
    "    x = []\n",
    "    y = []\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        if data.x is None:\n",
    "            num_nodes = data.batch.size(0)\n",
    "            data.x = torch.ones((num_nodes, 1), dtype=torch.float32, device=data.batch.device)\n",
    "        graph_embeds, node_embeds = encoder_model.get_embedding(data)\n",
    "        x.append(graph_embeds)\n",
    "        y.append(data.y)\n",
    "    x = torch.cat(x, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "\n",
    "    result = []\n",
    "    random.shuffle(seeds)\n",
    "    seeds = seeds.tolist()\n",
    "    for _ in np.arange(10):\n",
    "        random_seed = seeds.pop()\n",
    "        split = get_split(num_samples=x.size()[0], train_ratio=0.1, test_ratio=0.8, seed=random_seed)\n",
    "        result.append(LREvaluator()(x, y, split))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e16dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/data_splits/\" + args.dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0a75d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices, train_test_indices = [], [], []\n",
    "for i in range(10):\n",
    "    train_filename = os.path.join(path, '10fold_idx', 'train_idx-{}.txt'.format(i + 1))\n",
    "    test_filename = os.path.join(path, '10fold_idx', 'test_idx-{}.txt'.format(i + 1))\n",
    "    train_indices.append(torch.from_numpy(np.loadtxt(train_filename, dtype=int)).to(torch.long))\n",
    "    test_indices.append(torch.from_numpy(np.loadtxt(test_filename, dtype=int)).to(torch.long))\n",
    "\n",
    "if args.feature_augmentation:\n",
    "    file_name = 'train_test_splits_feat.txt'\n",
    "else:\n",
    "    file_name = 'train_test_splits_struct.txt'\n",
    "    \n",
    "train_test_filename = os.path.join(path, '10fold_idx', file_name)\n",
    "train_test_indices.append(torch.from_numpy(np.loadtxt(train_test_filename, dtype=int)).to(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "616c4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root='./data/'+args.dataset_name, name=args.dataset_name, \n",
    "                    pre_transform=T.Compose([edge_feature_transform]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b1ec712",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = torch.unique(dataset.y)\n",
    "args.n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c32b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.input_size = dataset.num_node_features\n",
    "args.pos_size = args.pos_enc_dim\n",
    "args.output_size = args.hidden_size\n",
    "args.edge_attr_size =  dataset.edge_attr.shape[1]\n",
    "args.edge_attr_v2_size =  dataset.edge_attr_v2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "217f09dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug1 = A.Identity()\n",
    "\n",
    "if args.feature_augmentation:\n",
    "    # Feature Augmentation\n",
    "    aug2 = A.RandomChoice([A.FeatureDropout(pf=0.1),\n",
    "                           A.FeatureMasking(pf=0.1),\n",
    "                           A.EdgeAttrMasking(pf=0.1)], 1)\n",
    "else:\n",
    "    # Structure Augmentation\n",
    "    aug2 = A.RandomChoice([A.RWSampling(num_seeds=1000, walk_length=10),\n",
    "                       A.NodeDropping(pn=0.1),\n",
    "                       A.EdgeRemoving(pe=0.1)], 1)\n",
    "\n",
    "model_1 = get_model(args)\n",
    "model_1.to(device)\n",
    "\n",
    "args.pos_attr = True\n",
    "args.input_size = args.pos_size\n",
    "model_2 = get_model(args)\n",
    "model_2.to(device)\n",
    "\n",
    "mlp1 = Projection(input_dim=args.hidden_size, output_dim=args.hidden_size)\n",
    "mlp2 = Projection(input_dim=args.hidden_size, output_dim=args.hidden_size)\n",
    "\n",
    "encoder_model = Encoder(model_1=model_1, model_2=model_2, mlp1=mlp1, mlp2=mlp2, aug1=aug1, aug2=aug2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b2640ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   1%|▎                          | 1/100 [00:02<04:55,  2.98s/it, loss=48.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   2%|▌                          | 2/100 [00:05<04:49,  2.96s/it, loss=37.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   3%|▊                          | 3/100 [00:08<04:45,  2.95s/it, loss=30.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   4%|█                          | 4/100 [00:11<04:42,  2.94s/it, loss=29.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   5%|█▍                           | 5/100 [00:14<04:42,  2.98s/it, loss=30]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   6%|█▋                           | 6/100 [00:17<04:39,  2.97s/it, loss=26]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   7%|█▉                         | 7/100 [00:20<04:36,  2.97s/it, loss=25.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   8%|██▏                        | 8/100 [00:23<04:34,  2.99s/it, loss=22.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   9%|██▌                          | 9/100 [00:26<04:31,  2.98s/it, loss=30]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  10%|██▊                         | 10/100 [00:29<04:29,  2.99s/it, loss=28]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  11%|██▊                       | 11/100 [00:32<04:25,  2.98s/it, loss=25.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  12%|███                       | 12/100 [00:35<04:21,  2.97s/it, loss=19.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  13%|███▍                      | 13/100 [00:38<04:17,  2.96s/it, loss=19.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  14%|███▋                      | 14/100 [00:41<04:14,  2.96s/it, loss=22.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  15%|███▉                      | 15/100 [00:44<04:12,  2.97s/it, loss=20.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  16%|████▏                     | 16/100 [00:47<04:08,  2.96s/it, loss=19.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  17%|████▍                     | 17/100 [00:50<04:05,  2.96s/it, loss=14.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  18%|████▋                     | 18/100 [00:53<04:02,  2.96s/it, loss=20.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  19%|████▉                     | 19/100 [00:56<03:59,  2.95s/it, loss=18.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 20, Loss: 1.1606\n",
      "Epoch: 20, Loss: 2.1216\n",
      "Epoch: 20, Loss: 2.8957\n",
      "Epoch: 20, Loss: 4.0673\n",
      "Epoch: 20, Loss: 4.4895\n",
      "Epoch: 20, Loss: 5.4081\n",
      "Epoch: 20, Loss: 6.1319\n",
      "Epoch: 20, Loss: 6.6626\n",
      "Epoch: 20, Loss: 7.1736\n",
      "Epoch: 20, Loss: 8.0045\n",
      "Epoch: 20, Loss: 9.1672\n",
      "Epoch: 20, Loss: 9.9855\n",
      "Epoch: 20, Loss: 11.5239\n",
      "Epoch: 20, Loss: 12.2690\n",
      "Epoch: 20, Loss: 12.8128\n",
      "Epoch: 20, Loss: 13.4073\n",
      "Epoch: 20, Loss: 13.9180\n",
      "Epoch: 20, Loss: 14.5479\n",
      "Epoch: 20, Loss: 15.7223\n",
      "Epoch: 20, Loss: 16.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  20%|█████▏                    | 20/100 [00:59<03:57,  2.97s/it, loss=17.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 17.6777\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  21%|█████▍                    | 21/100 [01:02<03:55,  2.99s/it, loss=20.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  22%|█████▋                    | 22/100 [01:05<03:53,  2.99s/it, loss=16.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  23%|█████▉                    | 23/100 [01:08<03:49,  2.98s/it, loss=22.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  24%|██████▋                     | 24/100 [01:11<03:48,  3.01s/it, loss=20]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  25%|██████▌                   | 25/100 [01:14<03:44,  3.00s/it, loss=11.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  26%|██████▊                   | 26/100 [01:17<03:42,  3.01s/it, loss=21.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  27%|███████                   | 27/100 [01:20<03:38,  2.99s/it, loss=15.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  28%|███████▎                  | 28/100 [01:23<03:35,  2.99s/it, loss=15.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  29%|███████▌                  | 29/100 [01:26<03:32,  2.99s/it, loss=13.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  30%|███████▊                  | 30/100 [01:29<03:28,  2.98s/it, loss=10.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  31%|████████                  | 31/100 [01:32<03:25,  2.99s/it, loss=15.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  32%|████████▎                 | 32/100 [01:35<03:22,  2.98s/it, loss=10.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  33%|█████████▏                  | 33/100 [01:38<03:19,  2.98s/it, loss=14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  34%|████████▊                 | 34/100 [01:41<03:15,  2.96s/it, loss=14.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  35%|█████████▊                  | 35/100 [01:44<03:12,  2.96s/it, loss=13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  36%|█████████▎                | 36/100 [01:47<03:09,  2.96s/it, loss=11.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  37%|█████████▌                | 37/100 [01:50<03:07,  2.97s/it, loss=18.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  38%|█████████▉                | 38/100 [01:53<03:04,  2.97s/it, loss=15.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  39%|██████████▏               | 39/100 [01:56<03:00,  2.97s/it, loss=14.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 40, Loss: 0.9035\n",
      "Epoch: 40, Loss: 1.7295\n",
      "Epoch: 40, Loss: 2.5726\n",
      "Epoch: 40, Loss: 3.5013\n",
      "Epoch: 40, Loss: 5.1637\n",
      "Epoch: 40, Loss: 23.8902\n",
      "Epoch: 40, Loss: 24.9658\n",
      "Epoch: 40, Loss: 31.8097\n",
      "Epoch: 40, Loss: 53.3478\n",
      "Epoch: 40, Loss: 102.0576\n",
      "Epoch: 40, Loss: 105.6865\n",
      "Epoch: 40, Loss: 108.9586\n",
      "Epoch: 40, Loss: 111.2120\n",
      "Epoch: 40, Loss: 114.9326\n",
      "Epoch: 40, Loss: 118.1201\n",
      "Epoch: 40, Loss: 121.2337\n",
      "Epoch: 40, Loss: 125.0317\n",
      "Epoch: 40, Loss: 127.9229\n",
      "Epoch: 40, Loss: 130.3880\n",
      "Epoch: 40, Loss: 133.4314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  40%|██████████▊                | 40/100 [01:59<02:58,  2.97s/it, loss=136]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Loss: 136.1973\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  41%|██████████▋               | 41/100 [02:01<02:55,  2.97s/it, loss=46.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  42%|██████████▉               | 42/100 [02:04<02:53,  2.98s/it, loss=35.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  43%|████████████                | 43/100 [02:07<02:49,  2.98s/it, loss=27]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  44%|███████████▍              | 44/100 [02:10<02:46,  2.97s/it, loss=29.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  45%|████████████▌               | 45/100 [02:14<02:46,  3.03s/it, loss=24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  46%|███████████▉              | 46/100 [02:17<02:43,  3.02s/it, loss=19.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  47%|████████████▏             | 47/100 [02:20<02:39,  3.01s/it, loss=19.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  48%|████████████▍             | 48/100 [02:23<02:36,  3.01s/it, loss=20.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  49%|████████████▋             | 49/100 [02:26<02:33,  3.00s/it, loss=23.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  50%|██████████████              | 50/100 [02:29<02:29,  3.00s/it, loss=23]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  51%|█████████████▎            | 51/100 [02:32<02:26,  2.99s/it, loss=19.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  52%|█████████████▌            | 52/100 [02:34<02:23,  2.98s/it, loss=20.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  53%|█████████████▊            | 53/100 [02:38<02:21,  3.00s/it, loss=19.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  54%|██████████████            | 54/100 [02:41<02:17,  2.99s/it, loss=17.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  55%|██████████████▎           | 55/100 [02:43<02:14,  2.98s/it, loss=14.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  56%|██████████████▌           | 56/100 [02:46<02:10,  2.97s/it, loss=12.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  57%|██████████████▊           | 57/100 [02:49<02:07,  2.97s/it, loss=21.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  58%|███████████████           | 58/100 [02:52<02:04,  2.98s/it, loss=16.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  59%|███████████████▎          | 59/100 [02:55<02:01,  2.97s/it, loss=21.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 60, Loss: 1.8754\n",
      "Epoch: 60, Loss: 2.8715\n",
      "Epoch: 60, Loss: 3.4196\n",
      "Epoch: 60, Loss: 4.0310\n",
      "Epoch: 60, Loss: 4.6706\n",
      "Epoch: 60, Loss: 5.4913\n",
      "Epoch: 60, Loss: 5.9637\n",
      "Epoch: 60, Loss: 6.5606\n",
      "Epoch: 60, Loss: 7.0125\n",
      "Epoch: 60, Loss: 7.6028\n",
      "Epoch: 60, Loss: 7.9552\n",
      "Epoch: 60, Loss: 8.6086\n",
      "Epoch: 60, Loss: 9.1887\n",
      "Epoch: 60, Loss: 10.1789\n",
      "Epoch: 60, Loss: 10.7713\n",
      "Epoch: 60, Loss: 12.2108\n",
      "Epoch: 60, Loss: 12.9425\n",
      "Epoch: 60, Loss: 15.3187\n",
      "Epoch: 60, Loss: 15.7757\n",
      "Epoch: 60, Loss: 16.2480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  60%|███████████████▌          | 60/100 [02:58<01:59,  2.98s/it, loss=17.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Loss: 17.7929\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  61%|███████████████▊          | 61/100 [03:01<01:55,  2.97s/it, loss=18.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  62%|████████████████          | 62/100 [03:04<01:52,  2.97s/it, loss=16.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  63%|████████████████▍         | 63/100 [03:07<01:49,  2.96s/it, loss=18.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  64%|████████████████▋         | 64/100 [03:10<01:47,  2.98s/it, loss=15.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  65%|████████████████▉         | 65/100 [03:13<01:44,  2.98s/it, loss=14.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  66%|█████████████████▏        | 66/100 [03:16<01:41,  3.00s/it, loss=11.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  67%|█████████████████▍        | 67/100 [03:19<01:38,  2.98s/it, loss=14.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  68%|███████████████████         | 68/100 [03:22<01:35,  2.98s/it, loss=13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  69%|█████████████████▉        | 69/100 [03:25<01:33,  3.00s/it, loss=15.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  70%|██████████████████▏       | 70/100 [03:28<01:29,  2.99s/it, loss=14.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  71%|███████████████████▉        | 71/100 [03:31<01:26,  2.98s/it, loss=14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  72%|██████████████████▋       | 72/100 [03:34<01:23,  2.98s/it, loss=10.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  73%|██████████████████▉       | 73/100 [03:37<01:20,  2.97s/it, loss=10.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  74%|███████████████████▏      | 74/100 [03:40<01:17,  2.99s/it, loss=12.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  75%|███████████████████▌      | 75/100 [03:43<01:14,  2.98s/it, loss=14.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  76%|████████████████████▌      | 76/100 [03:46<01:11,  2.98s/it, loss=9.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  77%|████████████████████      | 77/100 [03:49<01:08,  2.99s/it, loss=15.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  78%|████████████████████▎     | 78/100 [03:52<01:05,  2.99s/it, loss=10.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  79%|████████████████████▌     | 79/100 [03:55<01:03,  3.04s/it, loss=11.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 80, Loss: 0.3069\n",
      "Epoch: 80, Loss: 0.5990\n",
      "Epoch: 80, Loss: 1.1483\n",
      "Epoch: 80, Loss: 1.7736\n",
      "Epoch: 80, Loss: 1.9947\n",
      "Epoch: 80, Loss: 2.2362\n",
      "Epoch: 80, Loss: 2.8479\n",
      "Epoch: 80, Loss: 3.3948\n",
      "Epoch: 80, Loss: 3.8949\n",
      "Epoch: 80, Loss: 4.3448\n",
      "Epoch: 80, Loss: 4.7929\n",
      "Epoch: 80, Loss: 5.3110\n",
      "Epoch: 80, Loss: 6.0005\n",
      "Epoch: 80, Loss: 6.3920\n",
      "Epoch: 80, Loss: 6.5954\n",
      "Epoch: 80, Loss: 6.9360\n",
      "Epoch: 80, Loss: 7.7255\n",
      "Epoch: 80, Loss: 8.3702\n",
      "Epoch: 80, Loss: 9.1048\n",
      "Epoch: 80, Loss: 9.6553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  80%|████████████████████▊     | 80/100 [03:58<01:01,  3.06s/it, loss=10.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Loss: 10.0847\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  81%|██████████████████████▋     | 81/100 [04:01<00:57,  3.03s/it, loss=10]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  82%|█████████████████████▎    | 82/100 [04:04<00:54,  3.01s/it, loss=14.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  83%|█████████████████████▌    | 83/100 [04:07<00:50,  2.99s/it, loss=15.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  84%|███████████████████████▌    | 84/100 [04:10<00:47,  2.99s/it, loss=18]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  85%|██████████████████████    | 85/100 [04:13<00:45,  3.02s/it, loss=13.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  86%|██████████████████████▎   | 86/100 [04:16<00:42,  3.03s/it, loss=9.94]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  87%|████████████████████████▎   | 87/100 [04:19<00:39,  3.05s/it, loss=15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  88%|██████████████████████▉   | 88/100 [04:23<00:36,  3.06s/it, loss=10.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  89%|███████████████████████▏  | 89/100 [04:26<00:33,  3.09s/it, loss=8.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  90%|███████████████████████▍  | 90/100 [04:29<00:31,  3.11s/it, loss=11.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  91%|███████████████████████▋  | 91/100 [04:32<00:27,  3.11s/it, loss=10.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  92%|███████████████████████▉  | 92/100 [04:35<00:25,  3.13s/it, loss=11.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  93%|████████████████████████▏ | 93/100 [04:38<00:21,  3.14s/it, loss=10.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  94%|████████████████████████▍ | 94/100 [04:41<00:18,  3.14s/it, loss=7.89]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  95%|████████████████████████▋ | 95/100 [04:45<00:15,  3.14s/it, loss=11.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  96%|█████████████████████████▉ | 96/100 [04:48<00:12,  3.13s/it, loss=9.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  97%|█████████████████████████▏| 97/100 [04:51<00:09,  3.14s/it, loss=8.17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  98%|█████████████████████████▍| 98/100 [04:54<00:06,  3.13s/it, loss=7.12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  99%|█████████████████████████▋| 99/100 [04:57<00:03,  3.15s/it, loss=13.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 100, Loss: 0.7953\n",
      "Epoch: 100, Loss: 1.0679\n",
      "Epoch: 100, Loss: 1.4930\n",
      "Epoch: 100, Loss: 4.0917\n",
      "Epoch: 100, Loss: 4.4555\n",
      "Epoch: 100, Loss: 4.9483\n",
      "Epoch: 100, Loss: 5.4882\n",
      "Epoch: 100, Loss: 5.9513\n",
      "Epoch: 100, Loss: 6.6304\n",
      "Epoch: 100, Loss: 7.0621\n",
      "Epoch: 100, Loss: 7.3078\n",
      "Epoch: 100, Loss: 7.9137\n",
      "Epoch: 100, Loss: 8.3491\n",
      "Epoch: 100, Loss: 8.7846\n",
      "Epoch: 100, Loss: 9.0485\n",
      "Epoch: 100, Loss: 9.3614\n",
      "Epoch: 100, Loss: 10.1410\n",
      "Epoch: 100, Loss: 10.5808\n",
      "Epoch: 100, Loss: 10.9067\n",
      "Epoch: 100, Loss: 11.1652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T): 100%|█████████████████████████| 100/100 [05:00<00:00,  3.01s/it, loss=11.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 11.6797\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(encoder_model.parameters(), lr=args.lr, weight_decay=args.l2_wd)\n",
    "dataloader = DataLoader(dataset, batch_size=args.batch_size)\n",
    "with tqdm(total=100, desc='(T)') as pbar:\n",
    "    for epoch in range(1, 101):\n",
    "        loss = train(encoder_model, dataloader, optimizer, device)\n",
    "        pbar.set_postfix({'loss': loss})\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "067599ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|██████████| 5000/5000 [00:01<00:00, best test F1Mi=0.759, F1Ma=0.744]\n",
      "(LR): 100%|██████████| 5000/5000 [00:01<00:00, best test F1Mi=0.741, F1Ma=0.735]\n",
      "(LR): 100%|██████████| 5000/5000 [00:01<00:00, best test F1Mi=0.732, F1Ma=0.717]\n",
      "(LR): 100%|██████████| 5000/5000 [00:01<00:00, best test F1Mi=0.732, F1Ma=0.717]\n",
      "(LR): 100%|██████████| 5000/5000 [00:01<00:00, best test F1Mi=0.732, F1Ma=0.728]\n",
      "(LR): 100%|███████████| 5000/5000 [00:01<00:00, best test F1Mi=0.75, F1Ma=0.731]\n",
      "(LR): 100%|███████████| 5000/5000 [00:01<00:00, best test F1Mi=0.75, F1Ma=0.733]\n",
      "(LR): 100%|██████████| 5000/5000 [00:01<00:00, best test F1Mi=0.732, F1Ma=0.729]\n",
      "(LR): 100%|███████████| 5000/5000 [00:01<00:00, best test F1Mi=0.75, F1Ma=0.731]\n",
      "(LR): 100%|██████████| 5000/5000 [00:01<00:00, best test F1Mi=0.786, F1Ma=0.782]\n"
     ]
    }
   ],
   "source": [
    "test_result = test(encoder_model, dataloader, train_test_indices[0], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80f0c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_f1_values = [entry['micro_f1']*100 for entry in test_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f16ea92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc mean = 74.6429 ± 1.6071\n"
     ]
    }
   ],
   "source": [
    "np_micro_f1_values = np.array(micro_f1_values)\n",
    "micro_f1_mean = np.mean(np_micro_f1_values)\n",
    "micro_f1_std = np.std(np_micro_f1_values)\n",
    "uncertainty = np.max(np.abs(sns.utils.ci(sns.algorithms.bootstrap(np_micro_f1_values, func=np.mean, \n",
    "                                                                      n_boot=1000), 95) - np_micro_f1_values.mean()))\n",
    "\n",
    "print(f'test acc mean = {micro_f1_mean:.4f} ± {micro_f1_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79799fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
