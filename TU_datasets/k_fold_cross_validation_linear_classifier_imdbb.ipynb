{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb1beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import time\n",
    "from itertools import product\n",
    "from json import dumps\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.loader import DataListLoader, DataLoader\n",
    "from torch_geometric.nn import DataParallel\n",
    "from torch_geometric.seed import seed_everything\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data import DataLoader, Data\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pytorch_metric_learning.losses import NTXentLoss, VICRegLoss\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "import train_utils\n",
    "from data_utils import extract_edge_attributes\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from layers.input_encoder import LinearEncoder, LinearEdgeEncoder\n",
    "from layers.layer_utils import make_gnn_layer\n",
    "from models.GraphClassification import GraphClassification\n",
    "from models.model_utils import make_GNN\n",
    "\n",
    "import GCL.losses as L\n",
    "import GCL.augmentors as A\n",
    "from GCL.eval import get_split, SVMEvaluator, LREvaluator\n",
    "from GCL.models import DualBranchContrast\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4911d68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--feature_augmentation'], dest='feature_augmentation', nargs=None, const=None, default=True, type=<class 'bool'>, choices=None, required=False, help='If true, feature augmentation.', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Augmentation\n",
    "parser = argparse.ArgumentParser(f'arguments for training and testing')\n",
    "parser.add_argument('--save_dir', type=str, default='./save', help='Base directory for saving information.')\n",
    "parser.add_argument('--seed', type=int, default=2, help='Random seed for reproducibility.')\n",
    "parser.add_argument('--dataset_name', type=str, default=\"IMDBBINARY\",\n",
    "                    choices=(\"MUTAG\", \"PROTEINS\", \"PTC_MR\", \"IMDBBINARY\"), help='Name of dataset')\n",
    "parser.add_argument('--drop_prob', type=float, default=0.5,\n",
    "                    help='Probability of zeroing an activation in dropout layers.') \n",
    "parser.add_argument('--batch_size', type=int, default=32, help='Batch size per GPU. Scales automatically when \\\n",
    "                        multiple GPUs are available.')\n",
    "parser.add_argument(\"--parallel\", action=\"store_true\",\n",
    "                    help=\"If true, use DataParallel for multi-gpu training\")\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='Number of worker.')\n",
    "parser.add_argument('--load_path', type=str, default=None, help='Path to load as a model checkpoint.')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='Learning rate.')\n",
    "parser.add_argument('--l2_wd', type=float, default=3e-3, help='L2 weight decay.')\n",
    "parser.add_argument('--num_epochs', type=int, default=100, help='Number of epochs.')\n",
    "parser.add_argument(\"--hidden_size\", type=int, default=128, help=\"Hidden size of the model\")\n",
    "parser.add_argument(\"--embedding_size\", type=int, default=16, help=\"Output size of the logistic model\")\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"KHopGNNConv\",\n",
    "                    choices=(\"KHopGNNConv\"), help=\"Base GNN model\")\n",
    "parser.add_argument(\"--K\", type=int, default=2, help=\"Number of hop to consider\")\n",
    "parser.add_argument(\"--num_layer\", type=int, default=2, help=\"Number of layer for feature encoder\")\n",
    "parser.add_argument(\"--JK\", type=str, default=\"sum\", choices=(\"sum\", \"max\", \"mean\", \"attention\", \"last\", \"concat\"),\n",
    "                    help=\"Jumping knowledge method\")\n",
    "parser.add_argument(\"--residual\", default=True, action=\"store_true\", help=\"If true, use residual connection between each layer\")\n",
    "parser.add_argument(\"--virtual_node\", action=\"store_true\", default=False, \n",
    "                    help=\"If true, add virtual node information in each layer\")\n",
    "parser.add_argument(\"--eps\", type=float, default=0., help=\"Initial epsilon in GIN\")\n",
    "parser.add_argument(\"--train_eps\", action=\"store_true\", help=\"If true, the epsilon in GIN model is trainable\")\n",
    "parser.add_argument(\"--combine\", type=str, default=\"geometric\", choices=(\"attention\", \"geometric\"),\n",
    "                    help=\"Combine method in k-hop aggregation\")\n",
    "parser.add_argument(\"--pooling_method\", type=str, default=\"sum\", choices=(\"mean\", \"sum\", \"attention\"),\n",
    "                    help=\"Pooling method in graph classification\")\n",
    "parser.add_argument('--norm_type', type=str, default=\"Batch\",\n",
    "                    choices=(\"Batch\", \"Layer\", \"Instance\", \"GraphSize\", \"Pair\"),\n",
    "                    help=\"Normalization method in model\")\n",
    "parser.add_argument('--aggr', type=str, default=\"add\",\n",
    "                    help='Aggregation method in GNN layer, only works in GraphSAGE')\n",
    "parser.add_argument(\"--patience\", type=int, default=20, help=\"Patient epochs to wait before early stopping.\")\n",
    "parser.add_argument('--factor', type=float, default=0.5, help='Factor for reducing learning rate scheduler')\n",
    "parser.add_argument('--reprocess', action=\"store_true\", help='If true, reprocess the dataset')\n",
    "parser.add_argument('--search', action=\"store_true\", help='If true, search hyper-parameters')\n",
    "parser.add_argument(\"--pos_enc_dim\", type=int, default=6, help=\"Initial positional dim.\")\n",
    "parser.add_argument(\"--pos_attr\", type=bool, default=False, help=\"Positional attributes.\")\n",
    "parser.add_argument(\"--feature_augmentation\", type=bool, default=True, help=\"If true, feature augmentation.\")\n",
    "\n",
    "# Structure Augmentation\n",
    "# parser = argparse.ArgumentParser(f'arguments for training and testing')\n",
    "# parser.add_argument('--save_dir', type=str, default='./save', help='Base directory for saving information.')\n",
    "# parser.add_argument('--seed', type=int, default=2, help='Random seed for reproducibility.') # 4 -> 93\n",
    "# parser.add_argument('--dataset_name', type=str, default=\"IMDBBINARY\",\n",
    "#                     choices=(\"MUTAG\", \"PROTEINS\", \"PTC_MR\", \"IMDBBINARY\"), help='Name of dataset')\n",
    "# parser.add_argument('--drop_prob', type=float, default=0.5,\n",
    "#                     help='Probability of zeroing an activation in dropout layers.') # 0.5 -> 93\n",
    "# parser.add_argument('--batch_size', type=int, default=32, help='Batch size per GPU. Scales automatically when \\\n",
    "#                         multiple GPUs are available.') # 32 -> 93\n",
    "# parser.add_argument(\"--parallel\", action=\"store_true\",\n",
    "#                     help=\"If true, use DataParallel for multi-gpu training\")\n",
    "# parser.add_argument('--num_workers', type=int, default=0, help='Number of worker.')\n",
    "# parser.add_argument('--load_path', type=str, default=None, help='Path to load as a model checkpoint.')\n",
    "# parser.add_argument('--lr', type=float, default=0.001, help='Learning rate.') # 0.001 ->93\n",
    "# parser.add_argument('--l2_wd', type=float, default=3e-3, help='L2 weight decay.') # 3e-4 -> 93\n",
    "# parser.add_argument('--num_epochs', type=int, default=100, help='Number of epochs.') # 350 -> 93\n",
    "# parser.add_argument(\"--hidden_size\", type=int, default=128, help=\"Hidden size of the model\") # 128 -> 93\n",
    "# parser.add_argument(\"--embedding_size\", type=int, default=16, help=\"Output size of the logistic model\") # 16 -> 93\n",
    "# parser.add_argument(\"--model_name\", type=str, default=\"KHopGNNConv\",\n",
    "#                     choices=(\"KHopGNNConv\"), help=\"Base GNN model\")\n",
    "# parser.add_argument(\"--K\", type=int, default=2, help=\"Number of hop to consider\") # 2 -> 93\n",
    "# parser.add_argument(\"--num_layer\", type=int, default=2, help=\"Number of layer for feature encoder\") # 2 -> 93\n",
    "# parser.add_argument(\"--JK\", type=str, default=\"sum\", choices=(\"sum\", \"max\", \"mean\", \"attention\", \"last\", \"concat\"),\n",
    "#                     help=\"Jumping knowledge method\") # sum -> 93\n",
    "# parser.add_argument(\"--residual\", default=True, action=\"store_true\", help=\"If true, use residual connection between each layer\")\n",
    "# parser.add_argument(\"--virtual_node\", action=\"store_true\", default=False, \n",
    "#                     help=\"If true, add virtual node information in each layer\")\n",
    "# parser.add_argument(\"--eps\", type=float, default=0., help=\"Initial epsilon in GIN\")\n",
    "# parser.add_argument(\"--train_eps\", action=\"store_true\", help=\"If true, the epsilon in GIN model is trainable\")\n",
    "# parser.add_argument(\"--combine\", type=str, default=\"geometric\", choices=(\"attention\", \"geometric\"),\n",
    "#                     help=\"Combine method in k-hop aggregation\") # geometric -> 93\n",
    "# parser.add_argument(\"--pooling_method\", type=str, default=\"sum\", choices=(\"mean\", \"sum\", \"attention\"),\n",
    "#                     help=\"Pooling method in graph classification\") # sum -> 93\n",
    "# parser.add_argument('--norm_type', type=str, default=\"Batch\",\n",
    "#                     choices=(\"Batch\", \"Layer\", \"Instance\", \"GraphSize\", \"Pair\"),\n",
    "#                     help=\"Normalization method in model\") # Batch -> 93\n",
    "# parser.add_argument('--aggr', type=str, default=\"add\",\n",
    "#                     help='Aggregation method in GNN layer, only works in GraphSAGE')\n",
    "# parser.add_argument(\"--patience\", type=int, default=20, help=\"Patient epochs to wait before early stopping.\")\n",
    "# parser.add_argument('--factor', type=float, default=0.5, help='Factor for reducing learning rate scheduler')\n",
    "# parser.add_argument('--reprocess', action=\"store_true\", help='If true, reprocess the dataset')\n",
    "# parser.add_argument('--search', action=\"store_true\", help='If true, search hyper-parameters')\n",
    "# parser.add_argument(\"--pos_enc_dim\", type=int, default=6, help=\"Initial positional dim.\") # 6 -> 93\n",
    "# parser.add_argument(\"--pos_attr\", type=bool, default=False, help=\"Positional attributes.\")\n",
    "# parser.add_argument(\"--feature_augmentation\", type=bool, default=False, help=\"If true, feature augmentation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "595ed5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271a7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.name = args.model_name + \"_\" + str(args.K) + \"_\" + str(args.search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f72e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging and devices\n",
    "args.save_dir = train_utils.get_save_dir(args.save_dir, args.name, type=args.dataset_name)\n",
    "log = train_utils.get_logger(args.save_dir, args.name)\n",
    "device, args.gpu_ids = train_utils.get_available_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16ae1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05.13.24 14:16:43] Using single-gpu training\n"
     ]
    }
   ],
   "source": [
    "if len(args.gpu_ids) > 1 and args.parallel:\n",
    "    log.info(f'Using multi-gpu training')\n",
    "    args.parallel = True\n",
    "    loader = DataListLoader\n",
    "    args.batch_size *= max(1, len(args.gpu_ids))\n",
    "else:\n",
    "    log.info(f'Using single-gpu training')\n",
    "    args.parallel = False\n",
    "    loader = DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db947f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05.13.24 14:16:43] Using random seed 2...\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "seed = args.seed\n",
    "log.info(f'Using random seed {seed}...')\n",
    "seed_everything(seed)\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2254e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_feature_transform(g):\n",
    "    return extract_edge_attributes(g, args.pos_enc_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51999e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = str(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "704f9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args):\n",
    "    layer = make_gnn_layer(args)\n",
    "    init_emb = LinearEncoder(args.input_size, args.hidden_size, pos_attr=args.pos_attr)\n",
    "    init_edge_attr_emb = LinearEdgeEncoder(args.edge_attr_size, args.hidden_size, edge_attr=True)\n",
    "    init_edge_attr_v2_emb = LinearEdgeEncoder(args.edge_attr_v2_size, args.hidden_size, edge_attr=False)\n",
    "    \n",
    "    GNNModel = make_GNN(args)\n",
    "    \n",
    "    gnn = GNNModel(\n",
    "        num_layer=args.num_layer,\n",
    "        gnn_layer=layer,\n",
    "        JK=args.JK,\n",
    "        norm_type=args.norm_type,\n",
    "        init_emb=init_emb,\n",
    "        init_edge_attr_emb=init_edge_attr_emb,\n",
    "        init_edge_attr_v2_emb=init_edge_attr_v2_emb,\n",
    "        residual=args.residual,\n",
    "        virtual_node=args.virtual_node,\n",
    "        drop_prob=args.drop_prob)\n",
    "\n",
    "    model = GraphClassification(embedding_model=gnn,\n",
    "                                pooling_method=args.pooling_method,\n",
    "                                output_size=args.output_size)\n",
    "    \n",
    "    model.reset_parameters()\n",
    "\n",
    "    if args.parallel:\n",
    "        model = DataParallel(model, args.gpu_ids)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "863c9b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projection(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Projection, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x) + self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c138dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vicreg_loss(embeddings1, embeddings2, lambda_var=25, lambda_cov=25, mu=1):\n",
    "    \"\"\"\n",
    "    Calculate the VICReg loss between two sets of embeddings with the correct handling of covariance differences.\n",
    "    \n",
    "    Args:\n",
    "    embeddings1, embeddings2 (torch.Tensor): Embeddings from two views, shape (batch_size, feature_dim).\n",
    "    lambda_var (float): Coefficient for the variance loss.\n",
    "    lambda_cov (float): Coefficient for the covariance loss.\n",
    "    mu (float): Coefficient for the invariance loss.\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: The total VICReg loss.\n",
    "    \"\"\"\n",
    "    # Invariance Loss\n",
    "    invariance_loss = F.mse_loss(embeddings1, embeddings2)\n",
    "\n",
    "    # Variance Loss\n",
    "    def variance_loss(embeddings1, embeddings2):\n",
    "        mean_embeddings1 = embeddings1.mean(dim=0)\n",
    "        mean_embeddings2 = embeddings2.mean(dim=0)\n",
    "        \n",
    "        std_dev1 = torch.sqrt((embeddings1 - mean_embeddings1).var(dim=0) + 1e-4)\n",
    "        std_dev2 = torch.sqrt((embeddings2 - mean_embeddings2).var(dim=0) + 1e-4)\n",
    "        \n",
    "        return torch.mean(torch.abs(F.relu(1 - std_dev1) - F.relu(1 - std_dev2)))\n",
    "\n",
    "    variance_loss_value = variance_loss(embeddings1, embeddings2)\n",
    "\n",
    "    # Covariance Loss\n",
    "    def covariance_loss(embeddings1, embeddings2):\n",
    "        batch_size, feature_dim = embeddings1.size()\n",
    "        \n",
    "        embeddings_centered1 = embeddings1 - embeddings1.mean(dim=0)\n",
    "        embeddings_centered2 = embeddings2 - embeddings2.mean(dim=0)\n",
    "        \n",
    "        covariance_matrix1 = torch.matmul(embeddings_centered1.T, embeddings_centered1) / (batch_size - 1)\n",
    "        covariance_matrix2 = torch.matmul(embeddings_centered2.T, embeddings_centered2) / (batch_size - 1)\n",
    "        \n",
    "        covariance_matrix1.fill_diagonal_(0)\n",
    "        covariance_matrix2.fill_diagonal_(0)\n",
    "        \n",
    "        cov_diff = torch.abs(covariance_matrix1.pow(2) - covariance_matrix2.pow(2))\n",
    "        return cov_diff.sum() / feature_dim\n",
    "\n",
    "    covariance_loss_value = covariance_loss(embeddings1, embeddings2)\n",
    "\n",
    "    total_loss = mu * invariance_loss + lambda_var * variance_loss_value + lambda_cov * covariance_loss_value\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96b9e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, model_1, model_2, mlp1, mlp2, aug1, aug2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model_1 = model_1\n",
    "        self.model_2 = model_2\n",
    "        self.mlp1 = mlp1\n",
    "        self.mlp2 = mlp2\n",
    "        self.aug1 = aug1\n",
    "        self.aug2 = aug2\n",
    "        \n",
    "    def get_embedding(self, data):\n",
    "        z, g = self.model_1(data)\n",
    "        z_pos, g_pos = self.model_2(data)\n",
    "        \n",
    "        z = self.mlp1(z)\n",
    "        g = self.mlp2(g)\n",
    "        \n",
    "        z_pos = self.mlp1(z_pos)\n",
    "        g_pos = self.mlp2(g_pos)\n",
    "\n",
    "        g = torch.cat((g, g_pos), 1)\n",
    "        z = torch.cat((z, z_pos), 1)\n",
    "\n",
    "        return g.detach(), z.detach()\n",
    "\n",
    "    def forward(self, data):\n",
    "        data1 = self.aug1(data.x, data.edge_index, data.y, data.pos, data.edge_attr,\n",
    "                          data.edge_attr_v2, data.batch, data.ptr)\n",
    "        data2 = self.aug2(data.x, data.edge_index, data.y, data.pos, data.edge_attr,\n",
    "                          data.edge_attr_v2, data.batch, data.ptr)\n",
    "        \n",
    "        # Structural features\n",
    "        z1, g1 = self.model_1(data1)\n",
    "        z2, g2 = self.model_1(data2)\n",
    "        \n",
    "        # Positional features\n",
    "        z1_pos, g1_pos = self.model_2(data1)\n",
    "        z2_pos, g2_pos = self.model_2(data2)\n",
    "        \n",
    "        h1, h2 = [self.mlp1(h) for h in [z1, z2]]\n",
    "        g1, g2 = [self.mlp2(g) for g in [g1, g2]]\n",
    "        \n",
    "        h1_pos, h2_pos = [self.mlp1(h_pos) for h_pos in [z1_pos, z2_pos]]\n",
    "        g1_pos, g2_pos = [self.mlp2(g_pos) for g_pos in [g1_pos, g2_pos]]\n",
    "        \n",
    "        h1 = torch.cat((h1, h1_pos), 1)\n",
    "        h2 = torch.cat((h2, h2_pos), 1)\n",
    "        g1 = torch.cat((g1, g1_pos), 1)\n",
    "        g2 = torch.cat((g2, g2_pos), 1)\n",
    "        \n",
    "        return h1, h2, g1, g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eb839d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder_model, dataloader, optimizer, device):\n",
    "    best = float(\"inf\")\n",
    "    cnt_wait = 0\n",
    "    best_t = 0\n",
    "    \n",
    "    loss_func = NTXentLoss(temperature=0.10)\n",
    "    \n",
    "    encoder_model.train()\n",
    "    epoch_loss = 0\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if data.x is None:\n",
    "            num_nodes = data.batch.size(0)\n",
    "            data.x = torch.ones((num_nodes, 1), dtype=torch.float32, device=data.batch.device)\n",
    "\n",
    "        h1, h2, g1, g2 = encoder_model(data)\n",
    "        \n",
    "        embeddings = torch.cat((g1, g2))\n",
    "        \n",
    "        # The same index corresponds to a positive pair\n",
    "        indices = torch.arange(0, g1.size(0), device=device)\n",
    "        labels = torch.cat((indices, indices))\n",
    "        \n",
    "        reg_loss = vicreg_loss(h1, h2, lambda_var=24, lambda_cov=24, mu=1)\n",
    "        loss = loss_func(embeddings, labels) + 0.005*reg_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            print(\"Epoch: {0}, Loss: {1:0.4f}\".format(epoch, epoch_loss))\n",
    "\n",
    "        if epoch_loss < best:\n",
    "            best = epoch_loss\n",
    "            best_t = epoch\n",
    "            cnt_wait = 0\n",
    "            torch.save(encoder_model.state_dict(), './pkl/best_model_'+ args.dataset_name + tag + '.pkl')\n",
    "        else:\n",
    "            cnt_wait += 1\n",
    "\n",
    "        if cnt_wait == args.patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "            \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1c74b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder_model, dataloader, seeds, device):\n",
    "    encoder_model.eval()\n",
    "    x = []\n",
    "    y = []\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        if data.x is None:\n",
    "            num_nodes = data.batch.size(0)\n",
    "            data.x = torch.ones((num_nodes, 1), dtype=torch.float32, device=data.batch.device)\n",
    "        graph_embeds, node_embeds = encoder_model.get_embedding(data)\n",
    "        x.append(graph_embeds)\n",
    "        y.append(data.y)\n",
    "    x = torch.cat(x, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "\n",
    "    result = []\n",
    "    random.shuffle(seeds)\n",
    "    seeds = seeds.tolist()\n",
    "    for _ in np.arange(10):\n",
    "        random_seed = seeds.pop()\n",
    "        split = get_split(num_samples=x.size()[0], train_ratio=0.1, test_ratio=0.8, seed=random_seed)\n",
    "        result.append(LREvaluator()(x, y, split))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68ee2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/data_splits/\" + args.dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b51201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices, train_test_indices = [], [], []\n",
    "for i in range(10):\n",
    "    train_filename = os.path.join(path, '10fold_idx', 'train_idx-{}.txt'.format(i + 1))\n",
    "    test_filename = os.path.join(path, '10fold_idx', 'test_idx-{}.txt'.format(i + 1))\n",
    "    train_indices.append(torch.from_numpy(np.loadtxt(train_filename, dtype=int)).to(torch.long))\n",
    "    test_indices.append(torch.from_numpy(np.loadtxt(test_filename, dtype=int)).to(torch.long))\n",
    "\n",
    "if args.feature_augmentation:\n",
    "    file_name = 'train_test_splits_feat.txt'\n",
    "else:\n",
    "    file_name = 'train_test_splits_struct.txt'\n",
    "    \n",
    "train_test_filename = os.path.join(path, '10fold_idx', file_name)\n",
    "train_test_indices.append(torch.from_numpy(np.loadtxt(train_test_filename, dtype=int)).to(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "298d99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root='./data/'+args.dataset_name, name=args.dataset_name, \n",
    "                    pre_transform=T.Compose([edge_feature_transform]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ef64fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum degree in the dataset\n",
    "max_degree = max([data.num_nodes for data in dataset])\n",
    "\n",
    "# Apply the OneHotDegree transform\n",
    "dataset.transform = T.OneHotDegree(max_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b9e99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = torch.unique(dataset.y)\n",
    "args.n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "165cd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.input_size = dataset.num_node_features\n",
    "args.pos_size = args.pos_enc_dim\n",
    "args.output_size = args.hidden_size\n",
    "args.edge_attr_size =  dataset.edge_attr.shape[1]\n",
    "args.edge_attr_v2_size =  dataset.edge_attr_v2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1700ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug1 = A.Identity()\n",
    "\n",
    "if args.feature_augmentation:\n",
    "    # Feature Augmentation\n",
    "    aug2 = A.RandomChoice([A.FeatureDropout(pf=0.1),\n",
    "                           A.FeatureMasking(pf=0.1),\n",
    "                           A.EdgeAttrMasking(pf=0.1)], 1)\n",
    "else:\n",
    "    # Structure Augmentation\n",
    "    aug2 = A.RandomChoice([A.RWSampling(num_seeds=1000, walk_length=10),\n",
    "                       A.NodeDropping(pn=0.1),\n",
    "                       A.EdgeRemoving(pe=0.1)], 1)\n",
    "\n",
    "model_1 = get_model(args)\n",
    "model_1.to(device)\n",
    "\n",
    "args.pos_attr = True\n",
    "args.input_size = args.pos_size\n",
    "model_2 = get_model(args)\n",
    "model_2.to(device)\n",
    "\n",
    "mlp1 = Projection(input_dim=args.hidden_size, output_dim=args.hidden_size)\n",
    "mlp2 = Projection(input_dim=args.hidden_size, output_dim=args.hidden_size)\n",
    "\n",
    "encoder_model = Encoder(model_1=model_1, model_2=model_2, mlp1=mlp1, mlp2=mlp2, aug1=aug1, aug2=aug2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3a67456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   1%|▎                          | 1/100 [00:01<02:37,  1.59s/it, loss=41.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   2%|▌                            | 2/100 [00:03<02:35,  1.59s/it, loss=30]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   3%|▊                          | 3/100 [00:04<02:36,  1.62s/it, loss=24.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   4%|█                          | 4/100 [00:06<02:35,  1.62s/it, loss=24.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   5%|█▎                         | 5/100 [00:08<02:34,  1.62s/it, loss=20.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   6%|█▌                         | 6/100 [00:09<02:35,  1.65s/it, loss=22.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   7%|█▉                         | 7/100 [00:11<02:44,  1.77s/it, loss=22.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   8%|██▏                        | 8/100 [00:13<02:47,  1.82s/it, loss=19.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):   9%|██▍                        | 9/100 [00:15<02:44,  1.81s/it, loss=18.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  10%|██▌                       | 10/100 [00:17<02:42,  1.81s/it, loss=19.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  11%|██▊                       | 11/100 [00:19<02:43,  1.84s/it, loss=15.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  12%|███                       | 12/100 [00:21<02:43,  1.86s/it, loss=16.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  13%|███▍                      | 13/100 [00:22<02:38,  1.82s/it, loss=17.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  14%|███▉                        | 14/100 [00:24<02:32,  1.77s/it, loss=15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  15%|███▉                      | 15/100 [00:26<02:30,  1.78s/it, loss=14.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  16%|████▏                     | 16/100 [00:28<02:29,  1.78s/it, loss=15.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  17%|████▍                     | 17/100 [00:29<02:29,  1.81s/it, loss=14.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  18%|████▋                     | 18/100 [00:31<02:27,  1.80s/it, loss=14.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  19%|████▉                     | 19/100 [00:33<02:22,  1.76s/it, loss=13.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 20, Loss: 0.8018\n",
      "Epoch: 20, Loss: 1.3217\n",
      "Epoch: 20, Loss: 1.9521\n",
      "Epoch: 20, Loss: 2.2329\n",
      "Epoch: 20, Loss: 2.9548\n",
      "Epoch: 20, Loss: 3.3453\n",
      "Epoch: 20, Loss: 3.9794\n",
      "Epoch: 20, Loss: 4.6585\n",
      "Epoch: 20, Loss: 4.8806\n",
      "Epoch: 20, Loss: 5.6367\n",
      "Epoch: 20, Loss: 6.0015\n",
      "Epoch: 20, Loss: 6.4242\n",
      "Epoch: 20, Loss: 7.4188\n",
      "Epoch: 20, Loss: 8.1070\n",
      "Epoch: 20, Loss: 9.2546\n",
      "Epoch: 20, Loss: 9.7973\n",
      "Epoch: 20, Loss: 10.3109\n",
      "Epoch: 20, Loss: 11.3082\n",
      "Epoch: 20, Loss: 11.8501\n",
      "Epoch: 20, Loss: 12.7711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  20%|█████▏                    | 20/100 [00:35<02:18,  1.73s/it, loss=13.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 13.2575\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  21%|█████▍                    | 21/100 [00:36<02:19,  1.77s/it, loss=12.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  22%|█████▋                    | 22/100 [00:38<02:15,  1.74s/it, loss=12.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  23%|█████▉                    | 23/100 [00:40<02:13,  1.73s/it, loss=13.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  24%|██████▏                   | 24/100 [00:42<02:10,  1.72s/it, loss=12.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  25%|███████                     | 25/100 [00:43<02:11,  1.75s/it, loss=14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  26%|██████▊                   | 26/100 [00:45<02:12,  1.79s/it, loss=12.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  27%|███████                   | 27/100 [00:47<02:09,  1.77s/it, loss=11.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  28%|███████▎                  | 28/100 [00:49<02:07,  1.77s/it, loss=13.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  29%|████████                    | 29/100 [00:51<02:06,  1.79s/it, loss=13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  30%|███████▊                  | 30/100 [00:52<02:05,  1.80s/it, loss=14.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  31%|████████                  | 31/100 [00:54<02:02,  1.78s/it, loss=13.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  32%|████████▎                 | 32/100 [00:56<02:00,  1.77s/it, loss=12.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  33%|████████▌                 | 33/100 [00:58<01:59,  1.78s/it, loss=12.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  34%|████████▊                 | 34/100 [00:59<01:56,  1.77s/it, loss=11.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  35%|█████████▊                  | 35/100 [01:01<01:55,  1.78s/it, loss=12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  36%|█████████▎                | 36/100 [01:03<01:57,  1.83s/it, loss=15.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  37%|█████████▌                | 37/100 [01:05<01:54,  1.82s/it, loss=13.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  38%|█████████▉                | 38/100 [01:07<01:53,  1.83s/it, loss=12.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  39%|██████████▏               | 39/100 [01:09<01:50,  1.81s/it, loss=12.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 40, Loss: 0.6205\n",
      "Epoch: 40, Loss: 1.1973\n",
      "Epoch: 40, Loss: 1.8154\n",
      "Epoch: 40, Loss: 2.1808\n",
      "Epoch: 40, Loss: 2.7063\n",
      "Epoch: 40, Loss: 3.2115\n",
      "Epoch: 40, Loss: 3.8279\n",
      "Epoch: 40, Loss: 4.4118\n",
      "Epoch: 40, Loss: 4.8130\n",
      "Epoch: 40, Loss: 5.4853\n",
      "Epoch: 40, Loss: 6.0496\n",
      "Epoch: 40, Loss: 6.5315\n",
      "Epoch: 40, Loss: 7.1215\n",
      "Epoch: 40, Loss: 7.6543\n",
      "Epoch: 40, Loss: 8.4820\n",
      "Epoch: 40, Loss: 8.9534\n",
      "Epoch: 40, Loss: 10.6564\n",
      "Epoch: 40, Loss: 11.4853\n",
      "Epoch: 40, Loss: 12.4663\n",
      "Epoch: 40, Loss: 13.1848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  40%|██████████▍               | 40/100 [01:10<01:46,  1.78s/it, loss=13.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Loss: 13.7863\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  41%|██████████▋               | 41/100 [01:12<01:44,  1.78s/it, loss=14.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  42%|██████████▉               | 42/100 [01:14<01:42,  1.77s/it, loss=12.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  43%|████████████                | 43/100 [01:16<01:39,  1.75s/it, loss=13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  44%|███████████▍              | 44/100 [01:17<01:37,  1.74s/it, loss=12.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  45%|███████████▋              | 45/100 [01:19<01:33,  1.70s/it, loss=11.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  46%|███████████▉              | 46/100 [01:21<01:32,  1.71s/it, loss=11.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  47%|████████████▏             | 47/100 [01:22<01:30,  1.70s/it, loss=10.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  48%|████████████▍             | 48/100 [01:24<01:27,  1.69s/it, loss=11.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  49%|█████████████▋              | 49/100 [01:26<01:27,  1.72s/it, loss=13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  50%|█████████████             | 50/100 [01:27<01:25,  1.72s/it, loss=13.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  51%|█████████████▎            | 51/100 [01:29<01:22,  1.69s/it, loss=13.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  52%|█████████████▌            | 52/100 [01:31<01:21,  1.71s/it, loss=14.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  53%|█████████████▊            | 53/100 [01:32<01:20,  1.70s/it, loss=13.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  54%|███████████████             | 54/100 [01:34<01:20,  1.76s/it, loss=13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  55%|██████████████▎           | 55/100 [01:36<01:18,  1.74s/it, loss=11.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  56%|██████████████▌           | 56/100 [01:38<01:16,  1.74s/it, loss=11.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  57%|██████████████▊           | 57/100 [01:40<01:15,  1.76s/it, loss=11.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  58%|███████████████           | 58/100 [01:41<01:13,  1.76s/it, loss=15.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  59%|███████████████▎          | 59/100 [01:43<01:10,  1.72s/it, loss=13.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 60, Loss: 0.6312\n",
      "Epoch: 60, Loss: 1.2615\n",
      "Epoch: 60, Loss: 1.8313\n",
      "Epoch: 60, Loss: 2.1941\n",
      "Epoch: 60, Loss: 2.9089\n",
      "Epoch: 60, Loss: 3.1402\n",
      "Epoch: 60, Loss: 3.7088\n",
      "Epoch: 60, Loss: 4.1293\n",
      "Epoch: 60, Loss: 4.5111\n",
      "Epoch: 60, Loss: 4.9146\n",
      "Epoch: 60, Loss: 5.6745\n",
      "Epoch: 60, Loss: 6.0972\n",
      "Epoch: 60, Loss: 6.8374\n",
      "Epoch: 60, Loss: 7.6047\n",
      "Epoch: 60, Loss: 8.4850\n",
      "Epoch: 60, Loss: 9.0267\n",
      "Epoch: 60, Loss: 9.5421\n",
      "Epoch: 60, Loss: 9.8147\n",
      "Epoch: 60, Loss: 10.2655\n",
      "Epoch: 60, Loss: 10.9015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  60%|███████████████▌          | 60/100 [01:45<01:08,  1.70s/it, loss=11.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Loss: 11.3192\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  61%|███████████████▊          | 61/100 [01:46<01:05,  1.68s/it, loss=11.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  62%|████████████████          | 62/100 [01:48<01:05,  1.71s/it, loss=11.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  63%|████████████████▍         | 63/100 [01:50<01:03,  1.71s/it, loss=11.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  64%|████████████████▋         | 64/100 [01:52<01:02,  1.74s/it, loss=11.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  65%|████████████████▉         | 65/100 [01:54<01:02,  1.79s/it, loss=12.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  66%|█████████████████▏        | 66/100 [01:55<01:00,  1.77s/it, loss=11.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  67%|██████████████████▊         | 67/100 [01:57<00:58,  1.77s/it, loss=12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  68%|█████████████████▋        | 68/100 [01:59<00:57,  1.79s/it, loss=12.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  69%|█████████████████▉        | 69/100 [02:01<00:55,  1.79s/it, loss=12.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  70%|██████████████████▏       | 70/100 [02:02<00:53,  1.78s/it, loss=11.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  71%|██████████████████▍       | 71/100 [02:04<00:52,  1.82s/it, loss=11.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  72%|██████████████████▋       | 72/100 [02:06<00:51,  1.83s/it, loss=10.9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  73%|██████████████████▉       | 73/100 [02:08<00:48,  1.79s/it, loss=10.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  74%|███████████████████▏      | 74/100 [02:10<00:45,  1.76s/it, loss=10.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  75%|███████████████████▌      | 75/100 [02:11<00:43,  1.76s/it, loss=11.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  76%|███████████████████▊      | 76/100 [02:13<00:42,  1.75s/it, loss=11.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  77%|████████████████████      | 77/100 [02:15<00:39,  1.73s/it, loss=12.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  78%|████████████████████▎     | 78/100 [02:16<00:37,  1.71s/it, loss=12.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  79%|██████████████████████      | 79/100 [02:18<00:35,  1.69s/it, loss=12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 80, Loss: 0.6144\n",
      "Epoch: 80, Loss: 1.0675\n",
      "Epoch: 80, Loss: 1.7411\n",
      "Epoch: 80, Loss: 2.0727\n",
      "Epoch: 80, Loss: 2.6334\n",
      "Epoch: 80, Loss: 3.1489\n",
      "Epoch: 80, Loss: 3.7185\n",
      "Epoch: 80, Loss: 4.1054\n",
      "Epoch: 80, Loss: 4.4825\n",
      "Epoch: 80, Loss: 5.1618\n",
      "Epoch: 80, Loss: 5.5448\n",
      "Epoch: 80, Loss: 6.1589\n",
      "Epoch: 80, Loss: 6.8226\n",
      "Epoch: 80, Loss: 7.3698\n",
      "Epoch: 80, Loss: 8.1833\n",
      "Epoch: 80, Loss: 8.6367\n",
      "Epoch: 80, Loss: 9.3064\n",
      "Epoch: 80, Loss: 9.9860\n",
      "Epoch: 80, Loss: 10.3574\n",
      "Epoch: 80, Loss: 10.9192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  80%|████████████████████▊     | 80/100 [02:20<00:35,  1.76s/it, loss=11.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Loss: 11.3167\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  81%|█████████████████████     | 81/100 [02:22<00:34,  1.81s/it, loss=10.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  82%|█████████████████████▎    | 82/100 [02:24<00:31,  1.77s/it, loss=11.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  83%|███████████████████████▏    | 83/100 [02:25<00:29,  1.72s/it, loss=11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  84%|█████████████████████▊    | 84/100 [02:27<00:27,  1.72s/it, loss=11.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  85%|██████████████████████    | 85/100 [02:29<00:26,  1.75s/it, loss=10.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  86%|████████████████████████    | 86/100 [02:31<00:25,  1.79s/it, loss=11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  87%|██████████████████████▌   | 87/100 [02:32<00:22,  1.76s/it, loss=10.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  88%|██████████████████████▉   | 88/100 [02:34<00:20,  1.73s/it, loss=10.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  89%|████████████████████████   | 89/100 [02:36<00:19,  1.78s/it, loss=9.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  90%|█████████████████████████▏  | 90/100 [02:37<00:17,  1.73s/it, loss=10]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  91%|█████████████████████████▍  | 91/100 [02:39<00:15,  1.72s/it, loss=11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  92%|███████████████████████▉  | 92/100 [02:41<00:13,  1.70s/it, loss=10.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  93%|████████████████████████▏ | 93/100 [02:42<00:11,  1.69s/it, loss=10.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  94%|████████████████████████▍ | 94/100 [02:44<00:10,  1.68s/it, loss=11.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  95%|████████████████████████▋ | 95/100 [02:46<00:08,  1.67s/it, loss=10.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  96%|████████████████████████▉ | 96/100 [02:47<00:06,  1.67s/it, loss=10.8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  97%|█████████████████████████▏| 97/100 [02:49<00:05,  1.68s/it, loss=10.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  98%|█████████████████████████▍| 98/100 [02:51<00:03,  1.69s/it, loss=10.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T):  99%|█████████████████████████▋| 99/100 [02:52<00:01,  1.68s/it, loss=11.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n",
      "Epoch: 100, Loss: 0.9455\n",
      "Epoch: 100, Loss: 1.4267\n",
      "Epoch: 100, Loss: 2.2421\n",
      "Epoch: 100, Loss: 2.4136\n",
      "Epoch: 100, Loss: 2.8928\n",
      "Epoch: 100, Loss: 3.0924\n",
      "Epoch: 100, Loss: 3.6798\n",
      "Epoch: 100, Loss: 4.0857\n",
      "Epoch: 100, Loss: 4.3191\n",
      "Epoch: 100, Loss: 4.7429\n",
      "Epoch: 100, Loss: 5.2350\n",
      "Epoch: 100, Loss: 5.7046\n",
      "Epoch: 100, Loss: 6.2501\n",
      "Epoch: 100, Loss: 6.8645\n",
      "Epoch: 100, Loss: 7.4673\n",
      "Epoch: 100, Loss: 8.1054\n",
      "Epoch: 100, Loss: 8.5050\n",
      "Epoch: 100, Loss: 8.9397\n",
      "Epoch: 100, Loss: 9.3639\n",
      "Epoch: 100, Loss: 9.9828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T): 100%|█████████████████████████| 100/100 [02:54<00:00,  1.75s/it, loss=10.4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 10.3580\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(encoder_model.parameters(), lr=args.lr, weight_decay=args.l2_wd)\n",
    "dataloader = DataLoader(dataset, batch_size=args.batch_size)\n",
    "with tqdm(total=100, desc='(T)') as pbar:\n",
    "    for epoch in range(1, 101):\n",
    "        loss = train(encoder_model, dataloader, optimizer, device)\n",
    "        pbar.set_postfix({'loss': loss})\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f3a5166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(LR): 100%|███████████| 5000/5000 [00:01<00:00, best test F1Mi=0.77, F1Ma=0.768]\n",
      "(LR): 100%|███████████| 5000/5000 [00:01<00:00, best test F1Mi=0.74, F1Ma=0.738]\n",
      "(LR): 100%|███████████| 5000/5000 [00:01<00:00, best test F1Mi=0.75, F1Ma=0.748]\n",
      "(LR): 100%|███████████| 5000/5000 [00:01<00:00, best test F1Mi=0.75, F1Ma=0.741]\n",
      "(LR): 100%|███████████| 5000/5000 [00:01<00:00, best test F1Mi=0.74, F1Ma=0.739]\n",
      "(LR): 100%|███████████| 5000/5000 [00:01<00:00, best test F1Mi=0.76, F1Ma=0.758]\n",
      "(LR): 100%|███████████| 5000/5000 [00:01<00:00, best test F1Mi=0.77, F1Ma=0.767]\n",
      "(LR): 100%|████████████| 5000/5000 [00:01<00:00, best test F1Mi=0.74, F1Ma=0.74]\n",
      "(LR): 100%|████████████| 5000/5000 [00:01<00:00, best test F1Mi=0.78, F1Ma=0.78]\n",
      "(LR): 100%|███████████| 5000/5000 [00:01<00:00, best test F1Mi=0.75, F1Ma=0.746]\n"
     ]
    }
   ],
   "source": [
    "test_result = test(encoder_model, dataloader, train_test_indices[0], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8181c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_f1_values = [entry['micro_f1']*100 for entry in test_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28fa229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc mean = 75.5000 ± 1.3601\n"
     ]
    }
   ],
   "source": [
    "np_micro_f1_values = np.array(micro_f1_values)\n",
    "micro_f1_mean = np.mean(np_micro_f1_values)\n",
    "micro_f1_std = np.std(np_micro_f1_values)\n",
    "uncertainty = np.max(np.abs(sns.utils.ci(sns.algorithms.bootstrap(np_micro_f1_values, func=np.mean, \n",
    "                                                                      n_boot=1000), 95) - np_micro_f1_values.mean()))\n",
    "\n",
    "print(f'test acc mean = {micro_f1_mean:.4f} ± {micro_f1_std:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d2874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
